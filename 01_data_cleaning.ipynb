{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Usage in Seattle, 2005-2020\n",
    "\n",
    "## Data Cleaning\n",
    "\n",
    "The data is the [Checkouts by Title (Physical Items)](https://data.seattle.gov/Community/Checkouts-By-Title-Physical-Items-/5src-czff) dataset from [Seattle Open Data](https://data.seattle.gov/) and was downloaded on December 15, 2020.\n",
    "\n",
    "This notebook is designed to load a downloaded CSV file, merge it with item-specific information, convert it to a time-series-ready DataFrame, and save that as a compressed pickle file.\n",
    "\n",
    "*Note: This dataset is updated weekly; the more data, the longer the load times will be.*\n",
    "\n",
    "In the future, it may be a good idea to look into adding [API](https://dev.socrata.com/foundry/data.seattle.gov/5src-czff) calls into the pipeline, so as to quickly and easily add on the additional weekly data.\n",
    "\n",
    "*Note: Any cell that uses the built-in magic command* `%%time` *takes a significant (or at least not insignificant) time to run.*\n",
    "\n",
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard dataframe packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# saving packages\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "from functions.data_cleaning import status_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load checkout data\n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]\n",
    "\n",
    "Since the data set is so large, I'll specify only the columns that I want in the DataFrame. This will effectively drop the following columns:\n",
    "- `ID`\n",
    "- `CheckoutYear`\n",
    "- `CallNumber`\n",
    "- `BibNumber`\n",
    "- `ItemBarcode`\n",
    "- `ItemType`\n",
    "    \n",
    "I want to note that the `ItemType` and `Collection` columns are very similar, but the code in the `Collection` column contains more information within the `category_group` column that I add onto the DataFrame using the `data_dictionary.csv` file ([see below](#Load-other-info-from-data-dictionary-and-merge-onto-checkouts-dataset)). More specifically, the `ItemType` code yields mostly \"Miscellaneous\" results, whereas the `Collection` code yields differentiates between \"Fiction\" and \"Nonfiction\", among others. This could be useful information later on, so I found it best to drop the `ItemType` column.\n",
    "\n",
    "Note: In the future, I may consider using this [dataset](https://data.seattle.gov/Community/Library-Collection-Inventory/6vkj-f5xf) to add on branch information (i.e. which branch an item was checked out from), although this data is rather limited (due to privacy concerns) and incomplete (only appears to be collected beginning in 2017). In order to do that I would need to use the `BibNumber` column.\n",
    "\n",
    "#### ‚è∞ Cell below takes ~14.5 minutes to run. ‚è∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 20s, sys: 4min 39s, total: 9min\n",
      "Wall time: 14min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# columns to load\n",
    "usecols = ['Collection', 'ItemTitle', 'Subjects', 'CheckoutDateTime']\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv('data/Checkouts_By_Title__Physical_Items_.csv',\n",
    "#                  nrows=10000000,\n",
    "                 usecols=usecols)\n",
    "\n",
    "# rename columns to my preferred format\n",
    "df.columns = ['collection', 'title', 'subjects', 'date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: While it only took about 25 seconds to load 10 million rows, it takes about 25 minutes to load 106.5 million rows with the same number (5) of columns. In my latest update, I brought it down to 4 columns, which decreased load time to 15.5 minutes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106534901, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection</th>\n",
       "      <th>title</th>\n",
       "      <th>subjects</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nadvd</td>\n",
       "      <td>Firewall</td>\n",
       "      <td>Kidnapping Drama, Video recordings for the hea...</td>\n",
       "      <td>02/13/2008 07:38:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nanf</td>\n",
       "      <td>best baby shower book a complete guide for par...</td>\n",
       "      <td>Showers Parties</td>\n",
       "      <td>07/23/2008 02:53:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nyfic</td>\n",
       "      <td>Uglies</td>\n",
       "      <td>Fantasy, Teenage girls Fiction, Beauty Persona...</td>\n",
       "      <td>12/23/2009 04:20:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>napar</td>\n",
       "      <td>doula guide to birth secrets every pregnant wo...</td>\n",
       "      <td>Doulas, Childbirth</td>\n",
       "      <td>11/16/2010 12:04:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>canf</td>\n",
       "      <td>Salmon a cookbook</td>\n",
       "      <td>Cookery Salmon</td>\n",
       "      <td>04/26/2009 01:29:00 PM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  collection                                              title  \\\n",
       "0      nadvd                                           Firewall   \n",
       "1       nanf  best baby shower book a complete guide for par...   \n",
       "2      nyfic                                             Uglies   \n",
       "3      napar  doula guide to birth secrets every pregnant wo...   \n",
       "4       canf                                  Salmon a cookbook   \n",
       "\n",
       "                                            subjects                    date  \n",
       "0  Kidnapping Drama, Video recordings for the hea...  02/13/2008 07:38:00 PM  \n",
       "1                                    Showers Parties  07/23/2008 02:53:00 PM  \n",
       "2  Fantasy, Teenage girls Fiction, Beauty Persona...  12/23/2009 04:20:00 PM  \n",
       "3                                 Doulas, Childbirth  11/16/2010 12:04:00 PM  \n",
       "4                                     Cookery Salmon  04/26/2009 01:29:00 PM  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚è∞ Cell below takes ~3 minutes to run. ‚è∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.6 s, sys: 1min 9s, total: 1min 43s\n",
      "Wall time: 3min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "collection          0\n",
       "title          900912\n",
       "subjects      1649522\n",
       "date                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# check for nan values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE: Even checking for NaN values takes a significant amount of time with this many rows.*\n",
    "\n",
    "The most important columns (`collection` and `date`) have no NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collection    object\n",
       "title         object\n",
       "subjects      object\n",
       "date          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check datatypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert `date` column to datetime\n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'02/13/2008 07:38:00 PM'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at an example before conversion\n",
    "df.loc[0, 'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the format\n",
    "dt_format = '%m/%d/%Y %I:%M:%S %p'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚è∞ Cell below takes ~7 minutes to run. ‚è∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 27s, sys: 15.6 s, total: 6min 43s\n",
      "Wall time: 6min 46s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.date(2008, 2, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# convert to datetime, dropping the hour-minute-second stamp using the `dt.date` attribute\n",
    "df['date'] = pd.to_datetime(df.date, format=dt_format).dt.date\n",
    "\n",
    "# confirm it worked\n",
    "df.loc[0, 'date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load other info from data dictionary and merge onto checkouts dataset\n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>description</th>\n",
       "      <th>code_type</th>\n",
       "      <th>format_group</th>\n",
       "      <th>format_subgroup</th>\n",
       "      <th>category_group</th>\n",
       "      <th>category_subgroup</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cazover</td>\n",
       "      <td>CA7-zine collection oversize</td>\n",
       "      <td>ItemCollection</td>\n",
       "      <td>Print</td>\n",
       "      <td>Book</td>\n",
       "      <td>Periodical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>caziner</td>\n",
       "      <td>CA7-zine collection reference</td>\n",
       "      <td>ItemCollection</td>\n",
       "      <td>Print</td>\n",
       "      <td>Book</td>\n",
       "      <td>Periodical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cazval</td>\n",
       "      <td>CA7-zine collection valuable mat.</td>\n",
       "      <td>ItemCollection</td>\n",
       "      <td>Print</td>\n",
       "      <td>Book</td>\n",
       "      <td>Periodical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nga</td>\n",
       "      <td>Northgate Branch</td>\n",
       "      <td>Location</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hip</td>\n",
       "      <td>High Point Branch</td>\n",
       "      <td>Location</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      code                        description       code_type format_group  \\\n",
       "0  cazover       CA7-zine collection oversize  ItemCollection        Print   \n",
       "1  caziner      CA7-zine collection reference  ItemCollection        Print   \n",
       "2   cazval  CA7-zine collection valuable mat.  ItemCollection        Print   \n",
       "3      nga                   Northgate Branch        Location          NaN   \n",
       "4      hip                  High Point Branch        Location          NaN   \n",
       "\n",
       "  format_subgroup category_group category_subgroup age_group  \n",
       "0            Book     Periodical               NaN     Adult  \n",
       "1            Book     Periodical               NaN     Adult  \n",
       "2            Book     Periodical               NaN     Adult  \n",
       "3             NaN            NaN               NaN       NaN  \n",
       "4             NaN            NaN               NaN       NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "dd = pd.read_csv('data/data_dictionary.csv')\n",
    "\n",
    "# rename columns to my preferred format\n",
    "dd.columns = ['code', 'description', 'code_type', 'format_group', 'format_subgroup', \n",
    "              'category_group', 'category_subgroup', 'age_group']\n",
    "\n",
    "# take a look\n",
    "dd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape\n",
    "dd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code                 object\n",
       "description          object\n",
       "code_type            object\n",
       "format_group         object\n",
       "format_subgroup      object\n",
       "category_group       object\n",
       "category_subgroup    object\n",
       "age_group            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check datatypes\n",
    "dd.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I will only be using information from codes whose type is \"ItemCollection\", I'll subset the data dictionary down to just those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to only collection codes\n",
    "dd = dd[dd.code_type == 'ItemCollection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code                   0\n",
       "description            0\n",
       "code_type              0\n",
       "format_group           0\n",
       "format_subgroup       28\n",
       "category_group         2\n",
       "category_subgroup    391\n",
       "age_group              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for nan values\n",
    "dd.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, with the size of the eventual DataFrame in mind, I want to drop any unnecessary columns before merging, so I'll drop the following columns:\n",
    "- `description`, since that is superfluous information for this project\n",
    "- `code_type`, since that is superfluous information\n",
    "- `category_subgroup`, since that is mostly NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "dd.drop(columns=['description', 'code_type', 'category_subgroup'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of columns to convert\n",
    "to_convert = ['format_group', 'format_subgroup', 'category_group', 'age_group']\n",
    "\n",
    "# convert to category datatype\n",
    "dd[to_convert] = dd[to_convert].apply(pd.Categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code                 object\n",
       "format_group       category\n",
       "format_subgroup    category\n",
       "category_group     category\n",
       "age_group          category\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm new datatypes\n",
    "dd.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚è∞ Cell below takes ~4 minutes to run. ‚è∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min, sys: 1min 50s, total: 2min 51s\n",
      "Wall time: 4min 23s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection</th>\n",
       "      <th>title</th>\n",
       "      <th>subjects</th>\n",
       "      <th>date</th>\n",
       "      <th>code</th>\n",
       "      <th>format_group</th>\n",
       "      <th>format_subgroup</th>\n",
       "      <th>category_group</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nadvd</td>\n",
       "      <td>Firewall</td>\n",
       "      <td>Kidnapping Drama, Video recordings for the hea...</td>\n",
       "      <td>2008-02-13</td>\n",
       "      <td>nadvd</td>\n",
       "      <td>Media</td>\n",
       "      <td>Video Disc</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nadvd</td>\n",
       "      <td>Marley me</td>\n",
       "      <td>Comedy films, Married people Drama, Philadelph...</td>\n",
       "      <td>2009-07-03</td>\n",
       "      <td>nadvd</td>\n",
       "      <td>Media</td>\n",
       "      <td>Video Disc</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nadvd</td>\n",
       "      <td>Six feet under The complete fourth season</td>\n",
       "      <td>Video recordings for the hearing impaired, Pro...</td>\n",
       "      <td>2008-10-26</td>\n",
       "      <td>nadvd</td>\n",
       "      <td>Media</td>\n",
       "      <td>Video Disc</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nadvd</td>\n",
       "      <td>Doctor Who The next doctor</td>\n",
       "      <td>London England Drama, Doctor Who Fictitious ch...</td>\n",
       "      <td>2010-11-10</td>\n",
       "      <td>nadvd</td>\n",
       "      <td>Media</td>\n",
       "      <td>Video Disc</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nadvd</td>\n",
       "      <td>School ties</td>\n",
       "      <td>Antisemitism Drama, Video recordings for the h...</td>\n",
       "      <td>2008-12-28</td>\n",
       "      <td>nadvd</td>\n",
       "      <td>Media</td>\n",
       "      <td>Video Disc</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  collection                                      title  \\\n",
       "0      nadvd                                   Firewall   \n",
       "1      nadvd                                  Marley me   \n",
       "2      nadvd  Six feet under The complete fourth season   \n",
       "3      nadvd                 Doctor Who The next doctor   \n",
       "4      nadvd                                School ties   \n",
       "\n",
       "                                            subjects        date   code  \\\n",
       "0  Kidnapping Drama, Video recordings for the hea...  2008-02-13  nadvd   \n",
       "1  Comedy films, Married people Drama, Philadelph...  2009-07-03  nadvd   \n",
       "2  Video recordings for the hearing impaired, Pro...  2008-10-26  nadvd   \n",
       "3  London England Drama, Doctor Who Fictitious ch...  2010-11-10  nadvd   \n",
       "4  Antisemitism Drama, Video recordings for the h...  2008-12-28  nadvd   \n",
       "\n",
       "  format_group format_subgroup category_group age_group  \n",
       "0        Media      Video Disc        Fiction     Adult  \n",
       "1        Media      Video Disc        Fiction     Adult  \n",
       "2        Media      Video Disc        Fiction     Adult  \n",
       "3        Media      Video Disc        Fiction     Adult  \n",
       "4        Media      Video Disc        Fiction     Adult  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# merge checkouts dataframe with info from data dictionary\n",
    "df_merged = df.merge(dd, left_on='collection', right_on='code')\n",
    "\n",
    "# take a look\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unnecessary columns\n",
    "\n",
    "I can now drop the `collection` and `code` columns, since those are no longer necessary.\n",
    "\n",
    "*NOTE: Using the Pandas method `.drop()` was taking well over an hour, so I'm going to try to subset it below, to see if that works any faster.*\n",
    "\n",
    "#### ‚è∞ Cell below takes ~38.5 minutes to run. ‚è∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 43s, sys: 18min 6s, total: 20min 50s\n",
      "Wall time: 44min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# drop columns\n",
    "df_merged.drop(columns=['collection', 'code'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set `date` column as index\n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]\n",
    "\n",
    "I've commented out the below code because now *this* has begun to consistently crash the kernel or zsh shell.\n",
    "\n",
    "After thinking more about it, I believe I will end up grouping by the date to get raw numbers for each day (not only total checkouts, but total print checkouts and fiction checkouts, etc.), which can be done before setting the `date` column as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # set `date` column as index and sort by index\n",
    "# df_merged = df_merged.set_index('date').sort_index()\n",
    "\n",
    "# # take a look\n",
    "# df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106503843, 7)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape\n",
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                object\n",
       "subjects             object\n",
       "date                 object\n",
       "format_group       category\n",
       "format_subgroup    category\n",
       "category_group     category\n",
       "age_group          category\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check datatypes\n",
    "df_merged.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: I may be able to drop even more columns (thinking especially of `title` and `subjects`), since I'll mostly be looking at sheer numbers of items checked out each day. I'll keep them in for now in case they end up being useful for EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíæ Save\n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]\n",
    "\n",
    "Due to some several kernel and zsh shell crashes, I'm going to try to save the DataFrame in batches of 10 million rows.\n",
    "\n",
    "*NOTE: Save time for 10 million rows takes about 5 minutes and the file size is 290MB. Increasing to 20 million rows seemed to increase save time considerably, and so was interrupted before completing.*\n",
    "\n",
    "‚è∞ The next cell will most likely take ~10 hours to run. ‚è∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # loop through index and multiples of 10 million\n",
    "# for ind, i in enumerate(range(0, 110000000, 10000000), 1):\n",
    "    \n",
    "#     # save (via compressed pickle) a dataframe of 10 million rows, use index for unique file names\n",
    "#     df_merged.iloc[i:i+10000000].to_pickle(f'data/seattle_lib_{ind}.pkl', compression='gzip')\n",
    "    \n",
    "#     # print status/time\n",
    "#     status_update(f'File {ind} out of 11 saved successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If anything gets stuck or your computer crashes, uncomment the code below, replace `n` with the part to start the new loop with, and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time = 00:53:04\n",
      "-----------------------\n",
      "File 5 out of 11 saved successfully\n",
      "\n",
      "Current time = 01:18:18\n",
      "-----------------------\n",
      "File 6 out of 11 saved successfully\n",
      "\n",
      "Current time = 02:35:13\n",
      "-----------------------\n",
      "File 7 out of 11 saved successfully\n",
      "\n",
      "Current time = 04:42:51\n",
      "-----------------------\n",
      "File 8 out of 11 saved successfully\n",
      "\n",
      "Current time = 06:06:44\n",
      "-----------------------\n",
      "File 9 out of 11 saved successfully\n",
      "\n",
      "Current time = 06:43:35\n",
      "-----------------------\n",
      "File 10 out of 11 saved successfully\n",
      "\n",
      "CPU times: user 28min 7s, sys: 2h 17min 27s, total: 2h 45min 35s\n",
      "Wall time: 6h 10min 4s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# n = ____\n",
    "\n",
    "# # loop through index and multiples of 10 million\n",
    "# for ind, i in enumerate(range((n-1)*10000000, 110000000, 10000000), n):\n",
    "    \n",
    "#     # save (via compressed pickle) a dataframe of 10 million rows, use index for unique file names\n",
    "#     df_merged.iloc[i:i+10000000].to_pickle(f'data/seattle_lib_{ind}.pkl', compression='gzip')\n",
    "    \n",
    "#     # print status/time\n",
    "#     status_update(f'File {ind} out of 11 saved successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíæ Load\n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time = 16:59:31\n",
      "-----------------------\n",
      "Begin load...\n",
      "\n",
      "Current time = 16:59:50\n",
      "-----------------------\n",
      "File 1 loaded successfully.\n",
      "\n",
      "Current time = 17:00:13\n",
      "-----------------------\n",
      "File 2 loaded successfully.\n",
      "\n",
      "Current time = 17:00:18\n",
      "-----------------------\n",
      "Concatenation successful. DataFrame consists of files 1-2.\n",
      "\n",
      "Current time = 17:00:35\n",
      "-----------------------\n",
      "File 3 loaded successfully.\n",
      "\n",
      "Current time = 17:00:37\n",
      "-----------------------\n",
      "Concatenation successful. DataFrame consists of files 1-3.\n",
      "\n",
      "Current time = 17:00:50\n",
      "-----------------------\n",
      "File 4 loaded successfully.\n",
      "\n",
      "Current time = 17:00:52\n",
      "-----------------------\n",
      "Concatenation successful. DataFrame consists of files 1-4.\n",
      "\n",
      "Current time = 17:01:09\n",
      "-----------------------\n",
      "File 5 loaded successfully.\n",
      "\n",
      "Current time = 17:01:41\n",
      "-----------------------\n",
      "Concatenation successful. DataFrame consists of files 1-5.\n",
      "\n",
      "Current time = 17:02:01\n",
      "-----------------------\n",
      "File 6 loaded successfully.\n",
      "\n",
      "Current time = 17:02:55\n",
      "-----------------------\n",
      "Concatenation successful. DataFrame consists of files 1-6.\n",
      "\n",
      "Current time = 17:03:21\n",
      "-----------------------\n",
      "File 7 loaded successfully.\n",
      "\n",
      "Current time = 17:04:46\n",
      "-----------------------\n",
      "Concatenation successful. DataFrame consists of files 1-7.\n",
      "\n",
      "Current time = 17:05:15\n",
      "-----------------------\n",
      "File 8 loaded successfully.\n",
      "\n",
      "Current time = 17:08:29\n",
      "-----------------------\n",
      "Concatenation successful. DataFrame consists of files 1-8.\n",
      "\n",
      "Current time = 17:09:06\n",
      "-----------------------\n",
      "File 9 loaded successfully.\n",
      "\n",
      "Current time = 17:12:56\n",
      "-----------------------\n",
      "Concatenation successful. DataFrame consists of files 1-9.\n",
      "\n",
      "Current time = 17:13:33\n",
      "-----------------------\n",
      "File 10 loaded successfully.\n",
      "\n",
      "Current time = 17:18:26\n",
      "-----------------------\n",
      "Concatenation successful. DataFrame consists of files 1-10.\n",
      "\n",
      "Current time = 17:18:57\n",
      "-----------------------\n",
      "File 11 loaded successfully.\n",
      "\n",
      "Current time = 17:24:31\n",
      "-----------------------\n",
      "Concatenation successful. DataFrame consists of files 1-11.\n",
      "\n",
      "Current time = 17:24:31\n",
      "-----------------------\n",
      "Load complete!\n",
      "\n",
      "CPU times: user 3min 50s, sys: 11min 9s, total: 14min 59s\n",
      "Wall time: 24min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# print status/time\n",
    "status_update('Begin load...')\n",
    "\n",
    "# load first part\n",
    "df = pd.read_pickle('data/seattle_lib_1.pkl', compression='gzip')\n",
    "\n",
    "# print status/time\n",
    "status_update('File 1 loaded successfully.')\n",
    "\n",
    "# iterate through 2-11\n",
    "for i in range(2, 12):\n",
    "\n",
    "    # load parts 2-11\n",
    "    to_add = pd.read_pickle(f'data/seattle_lib_{i}.pkl', compression='gzip')\n",
    "    \n",
    "    # print status/time\n",
    "    status_update(f'File {i} loaded successfully.')\n",
    "\n",
    "    # combine with previous part\n",
    "    df = pd.concat([df, to_add], ignore_index=True)\n",
    "    \n",
    "    # print status/time\n",
    "    status_update(f'Concatenation successful. DataFrame consists of files 1-{i}.')\n",
    "    \n",
    "# print status/time\n",
    "status_update('Load complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for duplicates and assumption of data integrity\n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]\n",
    "\n",
    "The issue of checking for duplicates with this dataset is that duplicates are acceptable! It is very likely that the same item is checked out from either the same or different branches on a single day. Multiple copies of a book, for example, can be stored in one branch or across several branches.\n",
    "\n",
    "NOTE: More investigation on the uniqueness of an item's call number could potentially solve this and allow me to check for actual duplicate rows. For the time being, I will assume the data is almost entirely, if not entirely, accurate.\n",
    "\n",
    "Checking for duplicates can be done by uncommenting and running the code below, although it may take quite awhile to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# df_merged[df_merged.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate categorical columns\n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]\n",
    "\n",
    "As shown above, the data has no NaN values for the all important `date` column (the count of which will be the target for my eventual time series models), which is great news.\n",
    "\n",
    "In terms of the categorical columns, I'll keep NaN values as they are, which means they simply won't factor into the category counts, but the items *will* still be counted in terms of how many items were checked out in a day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Print         59685137\n",
       "Media         46618209\n",
       "Other           200478\n",
       "Equipment           18\n",
       "Electronic           1\n",
       "Name: format_group, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format_group breakdown\n",
    "df.format_group.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `Equipment` and `Electronic` have so few observations, I'll lump those in with `Other` in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Book              59486648\n",
       "Video Disc        30287406\n",
       "Audio Disc        11238813\n",
       "Audiobook Disc     2695078\n",
       "Video Tape         1474457\n",
       "Kit                 626008\n",
       "Audiobook Tape      240328\n",
       "Music Score         130486\n",
       "Audio Tape           45946\n",
       "Folder               23900\n",
       "Data Disc             9886\n",
       "Periodical             623\n",
       "Document               471\n",
       "Art                    129\n",
       "Film                    81\n",
       "Name: format_subgroup, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format_subgroup breakdown\n",
    "df.format_subgroup.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think I can keep all these as is. They all seem to contain a fair amount of information and should interesting as part of a dashboard or in EDA in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fiction              65292861\n",
       "Nonfiction           37539002\n",
       "Miscellaneous         1734282\n",
       "Language              1679452\n",
       "Interlibrary Loan      192959\n",
       "Reference               57420\n",
       "On Order                 7422\n",
       "Temporary                  40\n",
       "WTBBL                      26\n",
       "Periodical                  0\n",
       "Name: category_group, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# category_group breakdown\n",
    "df.category_group.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these--`Miscellaneous`, `On Order`, `Temporary`--can be simplified into an `Other` category, since their current category doesn't provide any valuable information in terms of what the actual item is. I was originally considering including `Interlibrary Loan` in the `Other` category as well, but it may be interesting to see the numbers behind activity between the branches, so I'll leave it in for now.\n",
    "\n",
    "Based on some research, `WTBBL` stands for \"Washington Talking Book Library\" and includes materials for folks with visual impairments. I was interested in looking into this, but since the numbers are so low, I think I'll also group that into the `Other` category, as I assume this `category_group` value deal with *equipment* that can be rented.\n",
    "\n",
    "I will also convert `Periodical` to other; even though the count for it is 0, I assume this may relate to to items that have a `format_subgroup` value but no `category_group` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adult       71587854\n",
       "Juvenile    31006173\n",
       "Teen         3909816\n",
       "Name: age_group, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# category_group breakdown\n",
    "df.age_group.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything looks good here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform values in `format_group` and `category_group`\n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_values = ['Miscellaneous', 'On Order', 'Temporary', 'WTBBL', 'Periodical']\n",
    "\n",
    "# test['category_group'] = np.where(test.category_group in convert_values, 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.72 s, sys: 2.7 s, total: 9.42 s\n",
      "Wall time: 9.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Media, Print, Other]\n",
       "Categories (3, object): [Media, Print, Other]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# values to convert\n",
    "convert_values = ['Equipment', 'Electronic']\n",
    "\n",
    "# custom function to transform\n",
    "df['format_group'] = transform_category(df, 'format_group', convert_values, 'Other')\n",
    "\n",
    "# confirm\n",
    "df.format_group.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.36 s, sys: 2.23 s, total: 10.6 s\n",
      "Wall time: 10.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Fiction, Nonfiction, Language, Other, Interlibrary Loan, Reference, NaN]\n",
       "Categories (6, object): [Fiction, Nonfiction, Language, Other, Interlibrary Loan, Reference]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# values to convert\n",
    "convert_values = ['Miscellaneous', 'On Order', 'Temporary', 'WTBBL', 'Periodical']\n",
    "\n",
    "# custom function to transform\n",
    "df['category_group'] = transform_category(df, 'category_group', convert_values, 'Other')\n",
    "\n",
    "# confirm\n",
    "df.category_group.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy and count the necessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.28 s, sys: 6.04 s, total: 15.3 s\n",
      "Wall time: 15.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format_group_Media</th>\n",
       "      <th>format_group_Other</th>\n",
       "      <th>format_group_Print</th>\n",
       "      <th>format_subgroup_Art</th>\n",
       "      <th>format_subgroup_Audio Disc</th>\n",
       "      <th>format_subgroup_Audio Tape</th>\n",
       "      <th>format_subgroup_Audiobook Disc</th>\n",
       "      <th>format_subgroup_Audiobook Tape</th>\n",
       "      <th>format_subgroup_Book</th>\n",
       "      <th>format_subgroup_Data Disc</th>\n",
       "      <th>...</th>\n",
       "      <th>format_subgroup_Video Tape</th>\n",
       "      <th>category_group_Fiction</th>\n",
       "      <th>category_group_Interlibrary Loan</th>\n",
       "      <th>category_group_Language</th>\n",
       "      <th>category_group_Nonfiction</th>\n",
       "      <th>category_group_Other</th>\n",
       "      <th>category_group_Reference</th>\n",
       "      <th>age_group_Adult</th>\n",
       "      <th>age_group_Juvenile</th>\n",
       "      <th>age_group_Teen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   format_group_Media  format_group_Other  format_group_Print  \\\n",
       "0                   1                   0                   0   \n",
       "1                   1                   0                   0   \n",
       "2                   1                   0                   0   \n",
       "3                   1                   0                   0   \n",
       "4                   1                   0                   0   \n",
       "\n",
       "   format_subgroup_Art  format_subgroup_Audio Disc  \\\n",
       "0                    0                           0   \n",
       "1                    0                           0   \n",
       "2                    0                           0   \n",
       "3                    0                           0   \n",
       "4                    0                           0   \n",
       "\n",
       "   format_subgroup_Audio Tape  format_subgroup_Audiobook Disc  \\\n",
       "0                           0                               0   \n",
       "1                           0                               0   \n",
       "2                           0                               0   \n",
       "3                           0                               0   \n",
       "4                           0                               0   \n",
       "\n",
       "   format_subgroup_Audiobook Tape  format_subgroup_Book  \\\n",
       "0                               0                     0   \n",
       "1                               0                     0   \n",
       "2                               0                     0   \n",
       "3                               0                     0   \n",
       "4                               0                     0   \n",
       "\n",
       "   format_subgroup_Data Disc  ...  format_subgroup_Video Tape  \\\n",
       "0                          0  ...                           0   \n",
       "1                          0  ...                           0   \n",
       "2                          0  ...                           0   \n",
       "3                          0  ...                           0   \n",
       "4                          0  ...                           0   \n",
       "\n",
       "   category_group_Fiction  category_group_Interlibrary Loan  \\\n",
       "0                       1                                 0   \n",
       "1                       1                                 0   \n",
       "2                       1                                 0   \n",
       "3                       1                                 0   \n",
       "4                       1                                 0   \n",
       "\n",
       "   category_group_Language  category_group_Nonfiction  category_group_Other  \\\n",
       "0                        0                          0                     0   \n",
       "1                        0                          0                     0   \n",
       "2                        0                          0                     0   \n",
       "3                        0                          0                     0   \n",
       "4                        0                          0                     0   \n",
       "\n",
       "   category_group_Reference  age_group_Adult  age_group_Juvenile  \\\n",
       "0                         0                1                   0   \n",
       "1                         0                1                   0   \n",
       "2                         0                1                   0   \n",
       "3                         0                1                   0   \n",
       "4                         0                1                   0   \n",
       "\n",
       "   age_group_Teen  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# columns to dummy\n",
    "dummy_cols = ['format_group', 'format_subgroup', 'category_group', 'age_group']\n",
    "\n",
    "# dummy the columns\n",
    "dummy_df = pd.get_dummies(df[dummy_cols], prefix=dummy_cols)\n",
    "\n",
    "# take a look\n",
    "dummy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.31 s, sys: 12.3 s, total: 18.6 s\n",
      "Wall time: 22.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>format_group_Media</th>\n",
       "      <th>format_group_Other</th>\n",
       "      <th>format_group_Print</th>\n",
       "      <th>format_subgroup_Art</th>\n",
       "      <th>format_subgroup_Audio Disc</th>\n",
       "      <th>format_subgroup_Audio Tape</th>\n",
       "      <th>format_subgroup_Audiobook Disc</th>\n",
       "      <th>format_subgroup_Audiobook Tape</th>\n",
       "      <th>format_subgroup_Book</th>\n",
       "      <th>...</th>\n",
       "      <th>format_subgroup_Video Tape</th>\n",
       "      <th>category_group_Fiction</th>\n",
       "      <th>category_group_Interlibrary Loan</th>\n",
       "      <th>category_group_Language</th>\n",
       "      <th>category_group_Nonfiction</th>\n",
       "      <th>category_group_Other</th>\n",
       "      <th>category_group_Reference</th>\n",
       "      <th>age_group_Adult</th>\n",
       "      <th>age_group_Juvenile</th>\n",
       "      <th>age_group_Teen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-02-13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-07-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-10-26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-11-10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  format_group_Media  format_group_Other  format_group_Print  \\\n",
       "0  2008-02-13                   1                   0                   0   \n",
       "1  2009-07-03                   1                   0                   0   \n",
       "2  2008-10-26                   1                   0                   0   \n",
       "3  2010-11-10                   1                   0                   0   \n",
       "4  2008-12-28                   1                   0                   0   \n",
       "\n",
       "   format_subgroup_Art  format_subgroup_Audio Disc  \\\n",
       "0                    0                           0   \n",
       "1                    0                           0   \n",
       "2                    0                           0   \n",
       "3                    0                           0   \n",
       "4                    0                           0   \n",
       "\n",
       "   format_subgroup_Audio Tape  format_subgroup_Audiobook Disc  \\\n",
       "0                           0                               0   \n",
       "1                           0                               0   \n",
       "2                           0                               0   \n",
       "3                           0                               0   \n",
       "4                           0                               0   \n",
       "\n",
       "   format_subgroup_Audiobook Tape  format_subgroup_Book  ...  \\\n",
       "0                               0                     0  ...   \n",
       "1                               0                     0  ...   \n",
       "2                               0                     0  ...   \n",
       "3                               0                     0  ...   \n",
       "4                               0                     0  ...   \n",
       "\n",
       "   format_subgroup_Video Tape  category_group_Fiction  \\\n",
       "0                           0                       1   \n",
       "1                           0                       1   \n",
       "2                           0                       1   \n",
       "3                           0                       1   \n",
       "4                           0                       1   \n",
       "\n",
       "   category_group_Interlibrary Loan  category_group_Language  \\\n",
       "0                                 0                        0   \n",
       "1                                 0                        0   \n",
       "2                                 0                        0   \n",
       "3                                 0                        0   \n",
       "4                                 0                        0   \n",
       "\n",
       "   category_group_Nonfiction  category_group_Other  category_group_Reference  \\\n",
       "0                          0                     0                         0   \n",
       "1                          0                     0                         0   \n",
       "2                          0                     0                         0   \n",
       "3                          0                     0                         0   \n",
       "4                          0                     0                         0   \n",
       "\n",
       "   age_group_Adult  age_group_Juvenile  age_group_Teen  \n",
       "0                1                   0               0  \n",
       "1                1                   0               0  \n",
       "2                1                   0               0  \n",
       "3                1                   0               0  \n",
       "4                1                   0               0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# combine with date column\n",
    "df_counts = pd.concat([df.date, dummy_df], axis=1)\n",
    "\n",
    "# take a look\n",
    "df_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# group by date and get category total for each column\n",
    "df_counts = df_counts.groupby('date').agg('sum')\n",
    "\n",
    "# take a look\n",
    "df_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.4 s, sys: 9.07 s, total: 28.5 s\n",
      "Wall time: 33.7 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>format_group_Electronic</th>\n",
       "      <th>format_group_Equipment</th>\n",
       "      <th>format_group_Media</th>\n",
       "      <th>format_group_Other</th>\n",
       "      <th>format_group_Print</th>\n",
       "      <th>format_subgroup_Fiction</th>\n",
       "      <th>format_subgroup_Interlibrary Loan</th>\n",
       "      <th>format_subgroup_Language</th>\n",
       "      <th>format_subgroup_Nonfiction</th>\n",
       "      <th>...</th>\n",
       "      <th>category_group_Miscellaneous</th>\n",
       "      <th>category_group_Nonfiction</th>\n",
       "      <th>category_group_On Order</th>\n",
       "      <th>category_group_Periodical</th>\n",
       "      <th>category_group_Reference</th>\n",
       "      <th>category_group_Temporary</th>\n",
       "      <th>category_group_WTBBL</th>\n",
       "      <th>age_group_Adult</th>\n",
       "      <th>age_group_Juvenile</th>\n",
       "      <th>age_group_Teen</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-04-13</th>\n",
       "      <td>16471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6397.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>10041.0</td>\n",
       "      <td>8189.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>6719.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1143.0</td>\n",
       "      <td>6719.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11257.0</td>\n",
       "      <td>4613.0</td>\n",
       "      <td>601.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-14</th>\n",
       "      <td>10358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4015.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>6267.0</td>\n",
       "      <td>5276.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>4104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>619.0</td>\n",
       "      <td>4104.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6726.0</td>\n",
       "      <td>3381.0</td>\n",
       "      <td>251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-15</th>\n",
       "      <td>12896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5351.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>7494.0</td>\n",
       "      <td>6357.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>5166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>5166.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8795.0</td>\n",
       "      <td>3747.0</td>\n",
       "      <td>354.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-16</th>\n",
       "      <td>1358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>...</td>\n",
       "      <td>95.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-17</th>\n",
       "      <td>4555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1555.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2992.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>2145.0</td>\n",
       "      <td>...</td>\n",
       "      <td>203.0</td>\n",
       "      <td>2145.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3035.0</td>\n",
       "      <td>1349.0</td>\n",
       "      <td>171.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0  format_group_Electronic  format_group_Equipment  \\\n",
       "date                                                                 \n",
       "2005-04-13  16471                      0.0                     1.0   \n",
       "2005-04-14  10358                      0.0                     1.0   \n",
       "2005-04-15  12896                      0.0                     0.0   \n",
       "2005-04-16   1358                      0.0                     0.0   \n",
       "2005-04-17   4555                      0.0                     0.0   \n",
       "\n",
       "            format_group_Media  format_group_Other  format_group_Print  \\\n",
       "date                                                                     \n",
       "2005-04-13              6397.0                32.0             10041.0   \n",
       "2005-04-14              4015.0                75.0              6267.0   \n",
       "2005-04-15              5351.0                51.0              7494.0   \n",
       "2005-04-16               552.0                 0.0               806.0   \n",
       "2005-04-17              1555.0                 8.0              2992.0   \n",
       "\n",
       "            format_subgroup_Fiction  format_subgroup_Interlibrary Loan  \\\n",
       "date                                                                     \n",
       "2005-04-13                   8189.0                               32.0   \n",
       "2005-04-14                   5276.0                               73.0   \n",
       "2005-04-15                   6357.0                               50.0   \n",
       "2005-04-16                    567.0                                0.0   \n",
       "2005-04-17                   2017.0                                8.0   \n",
       "\n",
       "            format_subgroup_Language  format_subgroup_Nonfiction  ...  \\\n",
       "date                                                              ...   \n",
       "2005-04-13                     370.0                      6719.0  ...   \n",
       "2005-04-14                     272.0                      4104.0  ...   \n",
       "2005-04-15                     302.0                      5166.0  ...   \n",
       "2005-04-16                      29.0                       666.0  ...   \n",
       "2005-04-17                     177.0                      2145.0  ...   \n",
       "\n",
       "            category_group_Miscellaneous  category_group_Nonfiction  \\\n",
       "date                                                                  \n",
       "2005-04-13                        1143.0                     6719.0   \n",
       "2005-04-14                         619.0                     4104.0   \n",
       "2005-04-15                        1013.0                     5166.0   \n",
       "2005-04-16                          95.0                      666.0   \n",
       "2005-04-17                         203.0                     2145.0   \n",
       "\n",
       "            category_group_On Order  category_group_Periodical  \\\n",
       "date                                                             \n",
       "2005-04-13                      0.0                        0.0   \n",
       "2005-04-14                      2.0                        0.0   \n",
       "2005-04-15                      1.0                        0.0   \n",
       "2005-04-16                      0.0                        0.0   \n",
       "2005-04-17                      0.0                        0.0   \n",
       "\n",
       "            category_group_Reference  category_group_Temporary  \\\n",
       "date                                                             \n",
       "2005-04-13                      18.0                       0.0   \n",
       "2005-04-14                      12.0                       0.0   \n",
       "2005-04-15                       7.0                       0.0   \n",
       "2005-04-16                       1.0                       0.0   \n",
       "2005-04-17                       5.0                       0.0   \n",
       "\n",
       "            category_group_WTBBL  age_group_Adult  age_group_Juvenile  \\\n",
       "date                                                                    \n",
       "2005-04-13                   0.0          11257.0              4613.0   \n",
       "2005-04-14                   0.0           6726.0              3381.0   \n",
       "2005-04-15                   0.0           8795.0              3747.0   \n",
       "2005-04-16                   0.0            950.0               367.0   \n",
       "2005-04-17                   0.0           3035.0              1349.0   \n",
       "\n",
       "            age_group_Teen  \n",
       "date                        \n",
       "2005-04-13           601.0  \n",
       "2005-04-14           251.0  \n",
       "2005-04-15           354.0  \n",
       "2005-04-16            41.0  \n",
       "2005-04-17           171.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# combine with total checkouts per day\n",
    "df_counts = pd.concat([df.groupby('date').size(), df_counts], axis=1)\n",
    "\n",
    "# rename target column\n",
    "df_counts.columns[0] = 'total_checkouts'\n",
    "\n",
    "# take a look\n",
    "df_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRAVEYARD\n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 15s, sys: 1min 56s, total: 5min 12s\n",
      "Wall time: 5min 42s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "date        format_group  format_subgroup  category_group     age_group\n",
       "2008-01-02  Electronic    Art              Fiction            Adult        0\n",
       "                                                              Juvenile     0\n",
       "                                                              Teen         0\n",
       "                                           Interlibrary Loan  Adult        0\n",
       "                                                              Juvenile     0\n",
       "                                                                          ..\n",
       "2019-07-18  Print         Video Tape       Temporary          Juvenile     0\n",
       "                                                              Teen         0\n",
       "                                           WTBBL              Adult        0\n",
       "                                                              Juvenile     0\n",
       "                                                              Teen         0\n",
       "Length: 9139500, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cols = ['date', 'format_group', 'format_subgroup', 'category_group', 'age_group']\n",
    "\n",
    "test[cols].groupby(cols).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # list of columns to keep\n",
    "# keep_cols = ['title', 'subjects', 'date', 'format_group', 'format_subgroup',\n",
    "#              'category_group', 'age_group']\n",
    "\n",
    "# # drop columns\n",
    "# df_merged = df_merged[keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd[dd.code_type == 'ItemType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd[dd.code == 'nadvd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd[dd.code == 'acdvd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.code_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_item = dd[dd.code_type == 'ItemType'][['code', 'description', 'format_group', 'format_subgroup', 'category_group', \n",
    "             'category_subgroup', 'age_group']]\n",
    "\n",
    "dd_item.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_item2 = dd[dd.code_type == 'ItemCollection'][['code', 'description', 'format_group', 'format_subgroup', 'category_group', \n",
    "             'category_subgroup', 'age_group']]\n",
    "\n",
    "dd_item2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df.item_type.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_loc = dd[dd.code_type == 'Location'][['code', 'description']]\n",
    "\n",
    "dd_loc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.merge(dd_item, left_on='item_type', right_on='code')\n",
    "# test = test.merge(dd_loc, left_on='collection', right_on='code')\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.format_group.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.collection.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = df.merge(dd_item2, left_on='Collection', right_on='code')\n",
    "\n",
    "test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.groupby('format_group').category_group.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2.groupby('format_group').category_group.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd[dd.code == 'nybot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df.collection.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_loc.code.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[cod for cod in df.collection.unique() if cod in dd_loc.code.unique()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: Using the code below on 10 million rows is almost 39% faster and results in a saved file that is *nearly the same size as the original CSV file* (file is 23.22GB!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# df_merged.to_hdf('data/seattle_lib_temp_ten_mil__alt.hdf', 'mydata', format='table', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.title.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.title=='reader'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
