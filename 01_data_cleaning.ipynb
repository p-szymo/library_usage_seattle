{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Usage in Seattle, 2005-2020\n",
    "\n",
    "## Data Cleaning\n",
    "\n",
    "The data that is the basis for this project is the [Checkouts by Title (Physical Items)](https://data.seattle.gov/Community/Checkouts-By-Title-Physical-Items-/5src-czff) dataset from [Seattle Open Data](https://data.seattle.gov/). It was downloaded on December 15, 2020.\n",
    "\n",
    "This notebook is designed to load a downloaded CSV file, merge it with item-specific information, convert it to a time-series-ready DataFrame, and save that as a compressed pickle file.\n",
    "\n",
    "*Note: This dataset is updated weekly; the more data, the longer the load times will be.*\n",
    "\n",
    "In the future, it may be a good idea to look into adding [API](https://dev.socrata.com/foundry/data.seattle.gov/5src-czff) calls into the pipeline, so as to quickly and easily add on the additional weekly data.\n",
    "\n",
    "*Note: Any cell that uses the built-in magic command* `%%time` *takes a significant (or at least not insignificant) time to run.*\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "1. [Import required packages](#Import-required-packages)\n",
    "2. [Load checkouts data](#Load-checkout-data)\n",
    "3. [Convert date column to datetime](#Convert-date-column-to-datetime)\n",
    "4. [Load data dictionary and merge onto checkouts dataset](#Load-data-dictionary-and-merge-onto-checkouts-dataset)\n",
    "5. [Drop unnecessary columns](#Drop-unnecessary-columns)\n",
    "6. [Transform values found during EDA](#Transform-values-found-during-EDA)\n",
    "7. [Investigate categorical columns](#Investigate-categorical-columns)\n",
    "8. [Transform values in two columns](#Transform-values-in-format_group-and-category_group)\n",
    "9. [üíæ Save](#üíæ-Save-in-11-parts)\n",
    "10. [üíæ Load](#üíæ-Load-in-11-parts)\n",
    "11. [Checking for duplicates and assumption of data integrity](#Checking-for-duplicates-and-assumption-of-data-integrity)\n",
    "12. [Dummy and count the necessary columns](#Dummy-and-count-the-necessary-columns)\n",
    "13. [üíæ Save/Load item counts DataFrame](#üíæ-Save/Load-item-counts-DataFrame)\n",
    "14. [Next notebook: EDA](#Next-notebook:-EDA)\n",
    "\n",
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard dataframe packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# custom functions\n",
    "from functions.data_cleaning import *\n",
    "\n",
    "# reload functions/libraries when edited\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load checkouts data\n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]\n",
    "\n",
    "Since the data set is so large, I'll specify only the columns that I want in the DataFrame. This will effectively drop the following columns:\n",
    "- `ID`\n",
    "- `CheckoutYear`\n",
    "- `CallNumber`\n",
    "- `BibNumber`\n",
    "- `ItemBarcode`\n",
    "- `ItemType`\n",
    "    \n",
    "I want to note that the `ItemType` and `Collection` columns are very similar, but the code in the `Collection` column contains more information within the `category_group` column that I add onto the DataFrame using the `data_dictionary.csv` file ([see below](#Load-other-info-from-data-dictionary-and-merge-onto-checkouts-dataset)). More specifically, the `ItemType` code yields mostly \"Miscellaneous\" results, whereas the `Collection` code yields differentiates between \"Fiction\" and \"Nonfiction\", among others. This could be useful information later on, so I found it best to drop the `ItemType` column.\n",
    "\n",
    "Note: In the future, I may consider using this [dataset](https://data.seattle.gov/Community/Library-Collection-Inventory/6vkj-f5xf) to add on branch information (i.e. which branch an item was checked out from), although this data is rather limited (due to privacy concerns) and incomplete (only appears to be collected beginning in 2017). In order to do that I would need to use the `BibNumber` column.\n",
    "\n",
    "#### ‚è∞ Cell below takes ~15 minutes to run. ‚è∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 26s, sys: 5min 21s, total: 9min 47s\n",
      "Wall time: 14min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# columns to load\n",
    "usecols = ['Collection', 'ItemTitle', 'Subjects', 'CheckoutDateTime']\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv('data/Checkouts_By_Title__Physical_Items_.csv', usecols=usecols)\n",
    "\n",
    "# rename columns to my preferred format\n",
    "df.columns = ['collection', 'title', 'subjects', 'date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: While it only took about 25 seconds to load 10 million rows, it takes about 25 minutes to load 106.5 million rows with the same number (5) of columns. In my latest update, I brought it down to 4 columns, which decreased load time to 15.5 minutes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106534901, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection</th>\n",
       "      <th>title</th>\n",
       "      <th>subjects</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nadvd</td>\n",
       "      <td>Firewall</td>\n",
       "      <td>Kidnapping Drama, Video recordings for the hea...</td>\n",
       "      <td>02/13/2008 07:38:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nanf</td>\n",
       "      <td>best baby shower book a complete guide for par...</td>\n",
       "      <td>Showers Parties</td>\n",
       "      <td>07/23/2008 02:53:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nyfic</td>\n",
       "      <td>Uglies</td>\n",
       "      <td>Fantasy, Teenage girls Fiction, Beauty Persona...</td>\n",
       "      <td>12/23/2009 04:20:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>napar</td>\n",
       "      <td>doula guide to birth secrets every pregnant wo...</td>\n",
       "      <td>Doulas, Childbirth</td>\n",
       "      <td>11/16/2010 12:04:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>canf</td>\n",
       "      <td>Salmon a cookbook</td>\n",
       "      <td>Cookery Salmon</td>\n",
       "      <td>04/26/2009 01:29:00 PM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  collection                                              title  \\\n",
       "0      nadvd                                           Firewall   \n",
       "1       nanf  best baby shower book a complete guide for par...   \n",
       "2      nyfic                                             Uglies   \n",
       "3      napar  doula guide to birth secrets every pregnant wo...   \n",
       "4       canf                                  Salmon a cookbook   \n",
       "\n",
       "                                            subjects                    date  \n",
       "0  Kidnapping Drama, Video recordings for the hea...  02/13/2008 07:38:00 PM  \n",
       "1                                    Showers Parties  07/23/2008 02:53:00 PM  \n",
       "2  Fantasy, Teenage girls Fiction, Beauty Persona...  12/23/2009 04:20:00 PM  \n",
       "3                                 Doulas, Childbirth  11/16/2010 12:04:00 PM  \n",
       "4                                     Cookery Salmon  04/26/2009 01:29:00 PM  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚è∞ Cell below takes ~4 minutes to run. ‚è∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44 s, sys: 1min 29s, total: 2min 13s\n",
      "Wall time: 3min 47s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "collection          0\n",
       "title          900912\n",
       "subjects      1649522\n",
       "date                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# check for nan values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE: Even checking for NaN values takes a significant amount of time with this many rows!*\n",
    "\n",
    "The most important columns (`collection` and `date`) have no NaN values.\n",
    "\n",
    "Also, [below](#Dummy-and-count-the-necessary-columns) I will account for these missing values by turning each column into a \"missing-or-not\" dummy column, in case there is any analysis to be drawn from that information, especially in relation to time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collection    object\n",
       "title         object\n",
       "subjects      object\n",
       "date          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check datatypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert `date` column to datetime\n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'02/13/2008 07:38:00 PM'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at an example before conversion\n",
    "df.loc[0, 'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the format\n",
    "dt_format = '%m/%d/%Y %I:%M:%S %p'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚è∞ Cell below takes ~7 minutes to run. ‚è∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 6s, sys: 12.9 s, total: 6min 19s\n",
      "Wall time: 6min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.date(2008, 2, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# convert to datetime, dropping the hour-minute-second stamp using the `dt.date` attribute\n",
    "df['date'] = pd.to_datetime(df.date, format=dt_format).dt.date\n",
    "\n",
    "# confirm it worked\n",
    "df.loc[0, 'date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data dictionary and merge onto checkouts dataset\n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>description</th>\n",
       "      <th>code_type</th>\n",
       "      <th>format_group</th>\n",
       "      <th>format_subgroup</th>\n",
       "      <th>category_group</th>\n",
       "      <th>category_subgroup</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cazover</td>\n",
       "      <td>CA7-zine collection oversize</td>\n",
       "      <td>ItemCollection</td>\n",
       "      <td>Print</td>\n",
       "      <td>Book</td>\n",
       "      <td>Periodical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>caziner</td>\n",
       "      <td>CA7-zine collection reference</td>\n",
       "      <td>ItemCollection</td>\n",
       "      <td>Print</td>\n",
       "      <td>Book</td>\n",
       "      <td>Periodical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cazval</td>\n",
       "      <td>CA7-zine collection valuable mat.</td>\n",
       "      <td>ItemCollection</td>\n",
       "      <td>Print</td>\n",
       "      <td>Book</td>\n",
       "      <td>Periodical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nga</td>\n",
       "      <td>Northgate Branch</td>\n",
       "      <td>Location</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hip</td>\n",
       "      <td>High Point Branch</td>\n",
       "      <td>Location</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      code                        description       code_type format_group  \\\n",
       "0  cazover       CA7-zine collection oversize  ItemCollection        Print   \n",
       "1  caziner      CA7-zine collection reference  ItemCollection        Print   \n",
       "2   cazval  CA7-zine collection valuable mat.  ItemCollection        Print   \n",
       "3      nga                   Northgate Branch        Location          NaN   \n",
       "4      hip                  High Point Branch        Location          NaN   \n",
       "\n",
       "  format_subgroup category_group category_subgroup age_group  \n",
       "0            Book     Periodical               NaN     Adult  \n",
       "1            Book     Periodical               NaN     Adult  \n",
       "2            Book     Periodical               NaN     Adult  \n",
       "3             NaN            NaN               NaN       NaN  \n",
       "4             NaN            NaN               NaN       NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "dd = pd.read_csv('data/data_dictionary.csv')\n",
    "\n",
    "# rename columns to my preferred format\n",
    "dd.columns = ['code', 'description', 'code_type', 'format_group', 'format_subgroup', \n",
    "              'category_group', 'category_subgroup', 'age_group']\n",
    "\n",
    "# take a look\n",
    "dd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape\n",
    "dd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code                 object\n",
       "description          object\n",
       "code_type            object\n",
       "format_group         object\n",
       "format_subgroup      object\n",
       "category_group       object\n",
       "category_subgroup    object\n",
       "age_group            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check datatypes\n",
    "dd.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I will only be using information from codes whose type is \"ItemCollection\", I'll subset the data dictionary down to just those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to only collection codes\n",
    "dd = dd[dd.code_type == 'ItemCollection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code                   0\n",
       "description            0\n",
       "code_type              0\n",
       "format_group           0\n",
       "format_subgroup       28\n",
       "category_group         2\n",
       "category_subgroup    391\n",
       "age_group              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for nan values\n",
    "dd.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, with the size of the eventual DataFrame in mind, I want to drop any unnecessary columns before merging, so I'll drop the following columns:\n",
    "- `description`, since that is superfluous information for this project\n",
    "- `code_type`, since that is superfluous information\n",
    "- `category_subgroup`, since that is mostly NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "dd.drop(columns=['description', 'code_type', 'category_subgroup'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of columns to convert\n",
    "to_convert = ['format_group', 'format_subgroup', 'category_group', 'age_group']\n",
    "\n",
    "# convert to category datatype\n",
    "dd[to_convert] = dd[to_convert].apply(pd.Categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code                 object\n",
       "format_group       category\n",
       "format_subgroup    category\n",
       "category_group     category\n",
       "age_group          category\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm new datatypes\n",
    "dd.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚è∞ Cell below takes ~4.5 minutes to run. ‚è∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min, sys: 1min 53s, total: 2min 54s\n",
      "Wall time: 4min 16s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection</th>\n",
       "      <th>title</th>\n",
       "      <th>subjects</th>\n",
       "      <th>date</th>\n",
       "      <th>code</th>\n",
       "      <th>format_group</th>\n",
       "      <th>format_subgroup</th>\n",
       "      <th>category_group</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nadvd</td>\n",
       "      <td>Firewall</td>\n",
       "      <td>Kidnapping Drama, Video recordings for the hea...</td>\n",
       "      <td>2008-02-13</td>\n",
       "      <td>nadvd</td>\n",
       "      <td>Media</td>\n",
       "      <td>Video Disc</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nadvd</td>\n",
       "      <td>Marley me</td>\n",
       "      <td>Comedy films, Married people Drama, Philadelph...</td>\n",
       "      <td>2009-07-03</td>\n",
       "      <td>nadvd</td>\n",
       "      <td>Media</td>\n",
       "      <td>Video Disc</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nadvd</td>\n",
       "      <td>Six feet under The complete fourth season</td>\n",
       "      <td>Video recordings for the hearing impaired, Pro...</td>\n",
       "      <td>2008-10-26</td>\n",
       "      <td>nadvd</td>\n",
       "      <td>Media</td>\n",
       "      <td>Video Disc</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nadvd</td>\n",
       "      <td>Doctor Who The next doctor</td>\n",
       "      <td>London England Drama, Doctor Who Fictitious ch...</td>\n",
       "      <td>2010-11-10</td>\n",
       "      <td>nadvd</td>\n",
       "      <td>Media</td>\n",
       "      <td>Video Disc</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nadvd</td>\n",
       "      <td>School ties</td>\n",
       "      <td>Antisemitism Drama, Video recordings for the h...</td>\n",
       "      <td>2008-12-28</td>\n",
       "      <td>nadvd</td>\n",
       "      <td>Media</td>\n",
       "      <td>Video Disc</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  collection                                      title  \\\n",
       "0      nadvd                                   Firewall   \n",
       "1      nadvd                                  Marley me   \n",
       "2      nadvd  Six feet under The complete fourth season   \n",
       "3      nadvd                 Doctor Who The next doctor   \n",
       "4      nadvd                                School ties   \n",
       "\n",
       "                                            subjects        date   code  \\\n",
       "0  Kidnapping Drama, Video recordings for the hea...  2008-02-13  nadvd   \n",
       "1  Comedy films, Married people Drama, Philadelph...  2009-07-03  nadvd   \n",
       "2  Video recordings for the hearing impaired, Pro...  2008-10-26  nadvd   \n",
       "3  London England Drama, Doctor Who Fictitious ch...  2010-11-10  nadvd   \n",
       "4  Antisemitism Drama, Video recordings for the h...  2008-12-28  nadvd   \n",
       "\n",
       "  format_group format_subgroup category_group age_group  \n",
       "0        Media      Video Disc        Fiction     Adult  \n",
       "1        Media      Video Disc        Fiction     Adult  \n",
       "2        Media      Video Disc        Fiction     Adult  \n",
       "3        Media      Video Disc        Fiction     Adult  \n",
       "4        Media      Video Disc        Fiction     Adult  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# merge checkouts dataframe with info from data dictionary\n",
    "df_merged = df.merge(dd, left_on='collection', right_on='code')\n",
    "\n",
    "# take a look\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unnecessary columns\n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]\n",
    "\n",
    "I can now drop the `collection` and `code` columns, since those are no longer necessary.\n",
    "\n",
    "*NOTE: Using the Pandas method `.drop()` was taking well over an hour, so I'm going to try to subset it below, to see if that works any faster.*\n",
    "\n",
    "#### ‚è∞ Cell below takes ~45 minutes to run. ‚è∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 1s, sys: 19min 37s, total: 22min 38s\n",
      "Wall time: 43min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# drop columns\n",
    "df_merged.drop(columns=['collection', 'code'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: I may be able to drop even more columns (thinking especially of `title` and `subjects`), since I'll mostly be looking at sheer numbers of items checked out each day. I'll keep them in for now in case they end up being useful for EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform values found during EDA\n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]\n",
    "\n",
    "During EDA, I found the following values marked as `Print` in the `format_group` column and `Book` in the `format_subgroup` column, even though I believe they should be marked as `Equipment` and `Kit`:\n",
    "\n",
    "- `SPL HotSpot connecting Seattle`\n",
    "- `FlexTech Laptops`\n",
    "- `In Building Device Checkout`\n",
    "\n",
    "I will transform those values here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# items to transform\n",
    "to_transform = ['SPL HotSpot connecting Seattle', 'FlexTech Laptops',\n",
    "                'In Building Device Checkout']\n",
    "\n",
    "# custom function to transform format_group column\n",
    "df_merged['format_group'] = transform_category(\n",
    "    df_merged, 'title', 'format_group', to_transform, 'Equipment'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom function to transform format_subgroup column\n",
    "df_merged['format_subgroup'] = transform_category(\n",
    "    df_merged, 'title', 'format_subgroup', to_transform, 'Kit'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate categorical columns\n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]\n",
    "\n",
    "As shown above, the data has no NaN values for the all important `date` column (the count of which will be the target for my eventual time series models), which is great news.\n",
    "\n",
    "In terms of the categorical columns, I'll keep NaN values as they are, which means they simply won't factor into the category counts, but the items *will* still be counted in terms of how many items were checked out in a day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Print         59615970\n",
       "Media         46618209\n",
       "Other           200452\n",
       "Equipment        69211\n",
       "Electronic           1\n",
       "Name: format_group, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format_group breakdown\n",
    "df_merged.format_group.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `Electronic` has so few observations, I'll lump it in with `Other` in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Book              59417481\n",
       "Video Disc        30287406\n",
       "Audio Disc        11238813\n",
       "Audiobook Disc     2695078\n",
       "Video Tape         1474457\n",
       "Kit                 695201\n",
       "Audiobook Tape      240328\n",
       "Music Score         130486\n",
       "Audio Tape           45946\n",
       "Folder               23900\n",
       "Data Disc             9886\n",
       "Periodical             623\n",
       "Document               471\n",
       "Art                    129\n",
       "Film                    81\n",
       "Name: format_subgroup, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format_subgroup breakdown\n",
    "df_merged.format_subgroup.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think I can keep all these as is. They all seem to contain a fair amount of information and should be interesting as part of a dashboard or in EDA in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fiction              65292861\n",
       "Nonfiction           37539002\n",
       "Miscellaneous         1734282\n",
       "Language              1679452\n",
       "Interlibrary Loan      192959\n",
       "Reference               57420\n",
       "On Order                 7422\n",
       "Temporary                  40\n",
       "WTBBL                      26\n",
       "Periodical                  0\n",
       "Name: category_group, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# category_group breakdown\n",
    "df_merged.category_group.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these--`Miscellaneous`, `On Order`, `Temporary`--can be simplified into an `Other` category, since their current category doesn't provide any valuable information in terms of what the actual item is. I was originally considering including `Interlibrary Loan` in the `Other` category as well, but it may be interesting to see the numbers behind activity between the branches, so I'll leave it in for now.\n",
    "\n",
    "Based on some research, `WTBBL` stands for \"Washington Talking Book Library\" and includes materials for folks with visual impairments. I was interested in looking into this, but since the numbers are so low, I think I'll also group that into the `Other` category, as I assume this `category_group` value deal with *equipment* that can be rented.\n",
    "\n",
    "I will also convert `Periodical` to other; even though the count for it is 0, I assume this may relate to to items that have a `format_subgroup` value but no `category_group` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adult       71587854\n",
       "Juvenile    31006173\n",
       "Teen         3909816\n",
       "Name: age_group, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# category_group breakdown\n",
    "df_merged.age_group.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything looks good here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform values in `format_group` and `category_group`\n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]\n",
    "\n",
    "Here I'll consolidate a few values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Media, Print, Equipment, Other]\n",
       "Categories (4, object): [Media, Print, Equipment, Other]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# values to convert\n",
    "to_transform = ['Electronic']\n",
    "\n",
    "# custom function to transform\n",
    "df_merged['format_group'] = transform_category(\n",
    "    df_merged, 'format_group', 'format_group', to_transform, 'Other'\n",
    ")\n",
    "\n",
    "# confirm\n",
    "df_merged.format_group.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Fiction, Nonfiction, Language, Other, Interlibrary Loan, Reference, NaN]\n",
       "Categories (6, object): [Fiction, Nonfiction, Language, Other, Interlibrary Loan, Reference]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# values to convert\n",
    "to_transform = ['Miscellaneous', 'On Order', 'Temporary', 'WTBBL', 'Periodical']\n",
    "\n",
    "# custom function to transform\n",
    "df_merged['category_group'] = transform_category(\n",
    "    df_merged, 'category_group', 'category_group', to_transform, 'Other'\n",
    ")\n",
    "\n",
    "# confirm\n",
    "df_merged.category_group.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíæ Save in 11 parts\n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]\n",
    "\n",
    "Due to some several kernel and zsh shell crashes, I'm going to try to save the DataFrame in batches of 10 million rows.\n",
    "\n",
    "*NOTE: Save time for 10 million rows takes about 5 minutes and the file size is 290MB. Increasing to 20 million rows seemed to increase save time considerably, and so was interrupted before completing.*\n",
    "\n",
    "#### ‚è∞ Cell below will most likely take ~10 hours to run. ‚è∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time = 01:18:45\n",
      "-----------------------\n",
      "File 1 out of 11 saved successfully\n",
      "\n",
      "Current time = 01:24:19\n",
      "-----------------------\n",
      "File 2 out of 11 saved successfully\n",
      "\n",
      "Current time = 01:50:08\n",
      "-----------------------\n",
      "File 3 out of 11 saved successfully\n",
      "\n",
      "Current time = 02:00:07\n",
      "-----------------------\n",
      "File 4 out of 11 saved successfully\n",
      "\n",
      "Current time = 03:20:17\n",
      "-----------------------\n",
      "File 5 out of 11 saved successfully\n",
      "\n",
      "Current time = 03:48:17\n",
      "-----------------------\n",
      "File 6 out of 11 saved successfully\n",
      "\n",
      "Current time = 04:10:44\n",
      "-----------------------\n",
      "File 7 out of 11 saved successfully\n",
      "\n",
      "Current time = 05:30:07\n",
      "-----------------------\n",
      "File 8 out of 11 saved successfully\n",
      "\n",
      "Current time = 06:43:37\n",
      "-----------------------\n",
      "File 9 out of 11 saved successfully\n",
      "\n",
      "Current time = 08:20:01\n",
      "-----------------------\n",
      "File 10 out of 11 saved successfully\n",
      "\n",
      "Current time = 09:07:15\n",
      "-----------------------\n",
      "File 11 out of 11 saved successfully\n",
      "\n",
      "CPU times: user 46min 42s, sys: 2h 55min 10s, total: 3h 41min 52s\n",
      "Wall time: 7h 53min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# loop through index and multiples of 10 million\n",
    "for ind, i in enumerate(range(0, 110000000, 10000000), 1):\n",
    "    \n",
    "    # save (via compressed pickle) a dataframe of 10 million rows, use index for unique file names\n",
    "    df_merged.iloc[i:i+10000000].to_pickle(f'data/seattle_lib_{ind}.pkl', compression='gzip')\n",
    "    \n",
    "    # print status/time\n",
    "    status_update(f'File {ind} out of 11 saved successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If anything gets stuck or your computer crashes, uncomment the code below, replace `n` with the part to start the new loop with, and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# n = ____\n",
    "\n",
    "# # loop through index and multiples of 10 million\n",
    "# for ind, i in enumerate(range((n-1)*10000000, 110000000, 10000000), n):\n",
    "    \n",
    "#     # save (via compressed pickle) a dataframe of 10 million rows, use index for unique file names\n",
    "#     df_merged.iloc[i:i+10000000].to_pickle(f'data/seattle_lib_{ind}.pkl', compression='gzip')\n",
    "    \n",
    "#     # print status/time\n",
    "#     status_update(f'File {ind} out of 11 saved successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíæ Load in 11 parts\n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]\n",
    "\n",
    "#### ‚è∞ Cell below takes ~25 minutes to run. ‚è∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update**: I've turned the above loop into a function, which can be run below, after uncommenting the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time = 09:07:17\n",
      "-----------------------\n",
      "Begin load...\n",
      "\n",
      "Current time = 09:07:37\n",
      "-----------------------\n",
      "File 1 loaded successfully.\n",
      "\n",
      "Current time = 09:07:48\n",
      "-----------------------\n",
      "File 2 loaded successfully.\n",
      "\n",
      "Current time = 09:07:49\n",
      "-----------------------\n",
      "Concatenation successful. DataFrame consists of files 1-2.\n",
      "\n",
      "Current time = 09:08:05\n",
      "-----------------------\n",
      "File 3 loaded successfully.\n",
      "\n",
      "Current time = 09:08:07\n",
      "-----------------------\n",
      "Concatenation successful. DataFrame consists of files 1-3.\n",
      "\n",
      "Current time = 09:08:19\n",
      "-----------------------\n",
      "File 4 loaded successfully.\n",
      "\n",
      "Current time = 09:08:24\n",
      "-----------------------\n",
      "Concatenation successful. DataFrame consists of files 1-4.\n",
      "\n",
      "Current time = 09:08:41\n",
      "-----------------------\n",
      "File 5 loaded successfully.\n",
      "\n",
      "Current time = 09:08:55\n",
      "-----------------------\n",
      "Concatenation successful. DataFrame consists of files 1-5.\n",
      "\n",
      "Current time = 09:09:12\n",
      "-----------------------\n",
      "File 6 loaded successfully.\n",
      "\n",
      "Current time = 09:10:07\n",
      "-----------------------\n",
      "Concatenation successful. DataFrame consists of files 1-6.\n",
      "\n",
      "Current time = 09:10:28\n",
      "-----------------------\n",
      "File 7 loaded successfully.\n",
      "\n",
      "Current time = 09:11:20\n",
      "-----------------------\n",
      "Concatenation successful. DataFrame consists of files 1-7.\n",
      "\n",
      "Current time = 09:11:47\n",
      "-----------------------\n",
      "File 8 loaded successfully.\n",
      "\n",
      "Current time = 09:13:39\n",
      "-----------------------\n",
      "Concatenation successful. DataFrame consists of files 1-8.\n",
      "\n",
      "Current time = 09:14:10\n",
      "-----------------------\n",
      "File 9 loaded successfully.\n",
      "\n",
      "Current time = 09:18:04\n",
      "-----------------------\n",
      "Concatenation successful. DataFrame consists of files 1-9.\n",
      "\n",
      "Current time = 09:18:38\n",
      "-----------------------\n",
      "File 10 loaded successfully.\n",
      "\n",
      "Current time = 09:23:12\n",
      "-----------------------\n",
      "Concatenation successful. DataFrame consists of files 1-10.\n",
      "\n",
      "Current time = 09:23:41\n",
      "-----------------------\n",
      "File 11 loaded successfully.\n",
      "\n",
      "Current time = 09:28:49\n",
      "-----------------------\n",
      "Concatenation successful. DataFrame consists of files 1-11.\n",
      "\n",
      "Current time = 09:28:49\n",
      "-----------------------\n",
      "Load complete!\n",
      "\n",
      "CPU times: user 3min 37s, sys: 10min 8s, total: 13min 46s\n",
      "Wall time: 21min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# uncomment to load complete item checkouts data\n",
    "df = load_multi_df(\n",
    "    'data/', 'seattle_lib_', 'pkl', 11, compression='gzip', verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106503843, 7)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for duplicates and assumption of data integrity\n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]\n",
    "\n",
    "The issue of checking for duplicates with this dataset is that duplicates are acceptable! It is very likely that the same item is checked out from either the same or different branches on a single day. Multiple copies of a book, for example, can be stored in one branch or across several branches.\n",
    "\n",
    "NOTE: More investigation on the uniqueness of an item's call number could potentially solve this and allow me to check for actual duplicate rows. For the time being, I will assume the data is almost entirely, if not entirely, accurate.\n",
    "\n",
    "Checking for duplicates can be done by uncommenting and running the code below, although it may take quite awhile to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# df[df.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy and count the necessary columns\n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format_group_Equipment</th>\n",
       "      <th>format_group_Media</th>\n",
       "      <th>format_group_Other</th>\n",
       "      <th>format_group_Print</th>\n",
       "      <th>format_subgroup_Art</th>\n",
       "      <th>format_subgroup_Audio Disc</th>\n",
       "      <th>format_subgroup_Audio Tape</th>\n",
       "      <th>format_subgroup_Audiobook Disc</th>\n",
       "      <th>format_subgroup_Audiobook Tape</th>\n",
       "      <th>format_subgroup_Book</th>\n",
       "      <th>...</th>\n",
       "      <th>format_subgroup_Video Tape</th>\n",
       "      <th>category_group_Fiction</th>\n",
       "      <th>category_group_Interlibrary Loan</th>\n",
       "      <th>category_group_Language</th>\n",
       "      <th>category_group_Nonfiction</th>\n",
       "      <th>category_group_Other</th>\n",
       "      <th>category_group_Reference</th>\n",
       "      <th>age_group_Adult</th>\n",
       "      <th>age_group_Juvenile</th>\n",
       "      <th>age_group_Teen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   format_group_Equipment  format_group_Media  format_group_Other  \\\n",
       "0                       0                   1                   0   \n",
       "1                       0                   1                   0   \n",
       "2                       0                   1                   0   \n",
       "3                       0                   1                   0   \n",
       "4                       0                   1                   0   \n",
       "\n",
       "   format_group_Print  format_subgroup_Art  format_subgroup_Audio Disc  \\\n",
       "0                   0                    0                           0   \n",
       "1                   0                    0                           0   \n",
       "2                   0                    0                           0   \n",
       "3                   0                    0                           0   \n",
       "4                   0                    0                           0   \n",
       "\n",
       "   format_subgroup_Audio Tape  format_subgroup_Audiobook Disc  \\\n",
       "0                           0                               0   \n",
       "1                           0                               0   \n",
       "2                           0                               0   \n",
       "3                           0                               0   \n",
       "4                           0                               0   \n",
       "\n",
       "   format_subgroup_Audiobook Tape  format_subgroup_Book  ...  \\\n",
       "0                               0                     0  ...   \n",
       "1                               0                     0  ...   \n",
       "2                               0                     0  ...   \n",
       "3                               0                     0  ...   \n",
       "4                               0                     0  ...   \n",
       "\n",
       "   format_subgroup_Video Tape  category_group_Fiction  \\\n",
       "0                           0                       1   \n",
       "1                           0                       1   \n",
       "2                           0                       1   \n",
       "3                           0                       1   \n",
       "4                           0                       1   \n",
       "\n",
       "   category_group_Interlibrary Loan  category_group_Language  \\\n",
       "0                                 0                        0   \n",
       "1                                 0                        0   \n",
       "2                                 0                        0   \n",
       "3                                 0                        0   \n",
       "4                                 0                        0   \n",
       "\n",
       "   category_group_Nonfiction  category_group_Other  category_group_Reference  \\\n",
       "0                          0                     0                         0   \n",
       "1                          0                     0                         0   \n",
       "2                          0                     0                         0   \n",
       "3                          0                     0                         0   \n",
       "4                          0                     0                         0   \n",
       "\n",
       "   age_group_Adult  age_group_Juvenile  age_group_Teen  \n",
       "0                1                   0               0  \n",
       "1                1                   0               0  \n",
       "2                1                   0               0  \n",
       "3                1                   0               0  \n",
       "4                1                   0               0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columns to dummy\n",
    "dummy_cols = ['format_group', 'format_subgroup', 'category_group', 'age_group']\n",
    "\n",
    "# dummy the columns\n",
    "dummy_df = pd.get_dummies(df[dummy_cols], prefix=dummy_cols)\n",
    "\n",
    "# take a look\n",
    "dummy_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to also create columns containing information on whether or not a value for the `title` and/or `subjects` column is missing. My hope is that, when analyzing this information in terms of time, I can get a sense of whether missing item information is a persistent issue, or if it has been corrected.\n",
    "\n",
    "#### ‚è∞ Cell below takes ~2 minutes to run. ‚è∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18 s, sys: 54.9 s, total: 1min 12s\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# `1` if title is missing, `0` if not\n",
    "df['missing_title'] = np.where(df.title.isna(), 1, 0)\n",
    "\n",
    "# `1` if subjects is missing, `0` if not\n",
    "df['missing_subjects'] = np.where(df.subjects.isna(), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.14 s, sys: 18.2 s, total: 25.3 s\n",
      "Wall time: 34.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>missing_title</th>\n",
       "      <th>missing_subjects</th>\n",
       "      <th>format_group_Equipment</th>\n",
       "      <th>format_group_Media</th>\n",
       "      <th>format_group_Other</th>\n",
       "      <th>format_group_Print</th>\n",
       "      <th>format_subgroup_Art</th>\n",
       "      <th>format_subgroup_Audio Disc</th>\n",
       "      <th>format_subgroup_Audio Tape</th>\n",
       "      <th>...</th>\n",
       "      <th>format_subgroup_Video Tape</th>\n",
       "      <th>category_group_Fiction</th>\n",
       "      <th>category_group_Interlibrary Loan</th>\n",
       "      <th>category_group_Language</th>\n",
       "      <th>category_group_Nonfiction</th>\n",
       "      <th>category_group_Other</th>\n",
       "      <th>category_group_Reference</th>\n",
       "      <th>age_group_Adult</th>\n",
       "      <th>age_group_Juvenile</th>\n",
       "      <th>age_group_Teen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-02-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-07-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-10-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-11-10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  missing_title  missing_subjects  format_group_Equipment  \\\n",
       "0  2008-02-13              0                 0                       0   \n",
       "1  2009-07-03              0                 0                       0   \n",
       "2  2008-10-26              0                 0                       0   \n",
       "3  2010-11-10              0                 0                       0   \n",
       "4  2008-12-28              0                 0                       0   \n",
       "\n",
       "   format_group_Media  format_group_Other  format_group_Print  \\\n",
       "0                   1                   0                   0   \n",
       "1                   1                   0                   0   \n",
       "2                   1                   0                   0   \n",
       "3                   1                   0                   0   \n",
       "4                   1                   0                   0   \n",
       "\n",
       "   format_subgroup_Art  format_subgroup_Audio Disc  \\\n",
       "0                    0                           0   \n",
       "1                    0                           0   \n",
       "2                    0                           0   \n",
       "3                    0                           0   \n",
       "4                    0                           0   \n",
       "\n",
       "   format_subgroup_Audio Tape  ...  format_subgroup_Video Tape  \\\n",
       "0                           0  ...                           0   \n",
       "1                           0  ...                           0   \n",
       "2                           0  ...                           0   \n",
       "3                           0  ...                           0   \n",
       "4                           0  ...                           0   \n",
       "\n",
       "   category_group_Fiction  category_group_Interlibrary Loan  \\\n",
       "0                       1                                 0   \n",
       "1                       1                                 0   \n",
       "2                       1                                 0   \n",
       "3                       1                                 0   \n",
       "4                       1                                 0   \n",
       "\n",
       "   category_group_Language  category_group_Nonfiction  category_group_Other  \\\n",
       "0                        0                          0                     0   \n",
       "1                        0                          0                     0   \n",
       "2                        0                          0                     0   \n",
       "3                        0                          0                     0   \n",
       "4                        0                          0                     0   \n",
       "\n",
       "   category_group_Reference  age_group_Adult  age_group_Juvenile  \\\n",
       "0                         0                1                   0   \n",
       "1                         0                1                   0   \n",
       "2                         0                1                   0   \n",
       "3                         0                1                   0   \n",
       "4                         0                1                   0   \n",
       "\n",
       "   age_group_Teen  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# combine with date column\n",
    "df_counts = pd.concat([df[['date', 'missing_title', 'missing_subjects']], dummy_df], axis=1)\n",
    "\n",
    "# take a look\n",
    "df_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106503843, 31)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape\n",
    "df_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚è∞ Cell below takes ~2 minutes to run. ‚è∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.2 s, sys: 52.8 s, total: 1min 34s\n",
      "Wall time: 1min 53s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_title</th>\n",
       "      <th>missing_subjects</th>\n",
       "      <th>format_group_Equipment</th>\n",
       "      <th>format_group_Media</th>\n",
       "      <th>format_group_Other</th>\n",
       "      <th>format_group_Print</th>\n",
       "      <th>format_subgroup_Art</th>\n",
       "      <th>format_subgroup_Audio Disc</th>\n",
       "      <th>format_subgroup_Audio Tape</th>\n",
       "      <th>format_subgroup_Audiobook Disc</th>\n",
       "      <th>...</th>\n",
       "      <th>format_subgroup_Video Tape</th>\n",
       "      <th>category_group_Fiction</th>\n",
       "      <th>category_group_Interlibrary Loan</th>\n",
       "      <th>category_group_Language</th>\n",
       "      <th>category_group_Nonfiction</th>\n",
       "      <th>category_group_Other</th>\n",
       "      <th>category_group_Reference</th>\n",
       "      <th>age_group_Adult</th>\n",
       "      <th>age_group_Juvenile</th>\n",
       "      <th>age_group_Teen</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-04-13</th>\n",
       "      <td>212</td>\n",
       "      <td>664</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6397.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>10041.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1874.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1878.0</td>\n",
       "      <td>8189.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>6719.0</td>\n",
       "      <td>1143.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11257.0</td>\n",
       "      <td>4613.0</td>\n",
       "      <td>601.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-14</th>\n",
       "      <td>123</td>\n",
       "      <td>541</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4015.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>6267.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1245.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>5276.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>4104.0</td>\n",
       "      <td>621.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6726.0</td>\n",
       "      <td>3381.0</td>\n",
       "      <td>251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-15</th>\n",
       "      <td>179</td>\n",
       "      <td>508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5351.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>7494.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1721.0</td>\n",
       "      <td>6357.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>5166.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8795.0</td>\n",
       "      <td>3747.0</td>\n",
       "      <td>354.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-16</th>\n",
       "      <td>7</td>\n",
       "      <td>56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>163.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-17</th>\n",
       "      <td>80</td>\n",
       "      <td>232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1555.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2992.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>480.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>2145.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3035.0</td>\n",
       "      <td>1349.0</td>\n",
       "      <td>171.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            missing_title  missing_subjects  format_group_Equipment  \\\n",
       "date                                                                  \n",
       "2005-04-13            212               664                     1.0   \n",
       "2005-04-14            123               541                     1.0   \n",
       "2005-04-15            179               508                     0.0   \n",
       "2005-04-16              7                56                     0.0   \n",
       "2005-04-17             80               232                     0.0   \n",
       "\n",
       "            format_group_Media  format_group_Other  format_group_Print  \\\n",
       "date                                                                     \n",
       "2005-04-13              6397.0                32.0             10041.0   \n",
       "2005-04-14              4015.0                75.0              6267.0   \n",
       "2005-04-15              5351.0                51.0              7494.0   \n",
       "2005-04-16               552.0                 0.0               806.0   \n",
       "2005-04-17              1555.0                 8.0              2992.0   \n",
       "\n",
       "            format_subgroup_Art  format_subgroup_Audio Disc  \\\n",
       "date                                                          \n",
       "2005-04-13                  0.0                      1874.0   \n",
       "2005-04-14                  0.0                      1245.0   \n",
       "2005-04-15                  0.0                      1462.0   \n",
       "2005-04-16                  0.0                       175.0   \n",
       "2005-04-17                  0.0                       499.0   \n",
       "\n",
       "            format_subgroup_Audio Tape  format_subgroup_Audiobook Disc  ...  \\\n",
       "date                                                                    ...   \n",
       "2005-04-13                        63.0                           217.0  ...   \n",
       "2005-04-14                        31.0                           164.0  ...   \n",
       "2005-04-15                        54.0                           187.0  ...   \n",
       "2005-04-16                         8.0                            31.0  ...   \n",
       "2005-04-17                        10.0                            47.0  ...   \n",
       "\n",
       "            format_subgroup_Video Tape  category_group_Fiction  \\\n",
       "date                                                             \n",
       "2005-04-13                      1878.0                  8189.0   \n",
       "2005-04-14                      1115.0                  5276.0   \n",
       "2005-04-15                      1721.0                  6357.0   \n",
       "2005-04-16                       163.0                   567.0   \n",
       "2005-04-17                       480.0                  2017.0   \n",
       "\n",
       "            category_group_Interlibrary Loan  category_group_Language  \\\n",
       "date                                                                    \n",
       "2005-04-13                              32.0                    370.0   \n",
       "2005-04-14                              73.0                    272.0   \n",
       "2005-04-15                              50.0                    302.0   \n",
       "2005-04-16                               0.0                     29.0   \n",
       "2005-04-17                               8.0                    177.0   \n",
       "\n",
       "            category_group_Nonfiction  category_group_Other  \\\n",
       "date                                                          \n",
       "2005-04-13                     6719.0                1143.0   \n",
       "2005-04-14                     4104.0                 621.0   \n",
       "2005-04-15                     5166.0                1014.0   \n",
       "2005-04-16                      666.0                  95.0   \n",
       "2005-04-17                     2145.0                 203.0   \n",
       "\n",
       "            category_group_Reference  age_group_Adult  age_group_Juvenile  \\\n",
       "date                                                                        \n",
       "2005-04-13                      18.0          11257.0              4613.0   \n",
       "2005-04-14                      12.0           6726.0              3381.0   \n",
       "2005-04-15                       7.0           8795.0              3747.0   \n",
       "2005-04-16                       1.0            950.0               367.0   \n",
       "2005-04-17                       5.0           3035.0              1349.0   \n",
       "\n",
       "            age_group_Teen  \n",
       "date                        \n",
       "2005-04-13           601.0  \n",
       "2005-04-14           251.0  \n",
       "2005-04-15           354.0  \n",
       "2005-04-16            41.0  \n",
       "2005-04-17           171.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# group by date and get category total for each column\n",
    "df_counts = df_counts.groupby('date').agg('sum')\n",
    "\n",
    "# take a look\n",
    "df_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_checkouts</th>\n",
       "      <th>missing_title</th>\n",
       "      <th>missing_subjects</th>\n",
       "      <th>format_group_Equipment</th>\n",
       "      <th>format_group_Media</th>\n",
       "      <th>format_group_Other</th>\n",
       "      <th>format_group_Print</th>\n",
       "      <th>format_subgroup_Art</th>\n",
       "      <th>format_subgroup_Audio Disc</th>\n",
       "      <th>format_subgroup_Audio Tape</th>\n",
       "      <th>...</th>\n",
       "      <th>format_subgroup_Video Tape</th>\n",
       "      <th>category_group_Fiction</th>\n",
       "      <th>category_group_Interlibrary Loan</th>\n",
       "      <th>category_group_Language</th>\n",
       "      <th>category_group_Nonfiction</th>\n",
       "      <th>category_group_Other</th>\n",
       "      <th>category_group_Reference</th>\n",
       "      <th>age_group_Adult</th>\n",
       "      <th>age_group_Juvenile</th>\n",
       "      <th>age_group_Teen</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-04-13</th>\n",
       "      <td>16471</td>\n",
       "      <td>212</td>\n",
       "      <td>664</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6397.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>10041.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1874.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1878.0</td>\n",
       "      <td>8189.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>6719.0</td>\n",
       "      <td>1143.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11257.0</td>\n",
       "      <td>4613.0</td>\n",
       "      <td>601.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-14</th>\n",
       "      <td>10358</td>\n",
       "      <td>123</td>\n",
       "      <td>541</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4015.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>6267.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1245.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>5276.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>4104.0</td>\n",
       "      <td>621.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6726.0</td>\n",
       "      <td>3381.0</td>\n",
       "      <td>251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-15</th>\n",
       "      <td>12896</td>\n",
       "      <td>179</td>\n",
       "      <td>508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5351.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>7494.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1721.0</td>\n",
       "      <td>6357.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>5166.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8795.0</td>\n",
       "      <td>3747.0</td>\n",
       "      <td>354.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-16</th>\n",
       "      <td>1358</td>\n",
       "      <td>7</td>\n",
       "      <td>56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>163.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-17</th>\n",
       "      <td>4555</td>\n",
       "      <td>80</td>\n",
       "      <td>232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1555.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2992.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>480.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>2145.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3035.0</td>\n",
       "      <td>1349.0</td>\n",
       "      <td>171.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            total_checkouts  missing_title  missing_subjects  \\\n",
       "date                                                           \n",
       "2005-04-13            16471            212               664   \n",
       "2005-04-14            10358            123               541   \n",
       "2005-04-15            12896            179               508   \n",
       "2005-04-16             1358              7                56   \n",
       "2005-04-17             4555             80               232   \n",
       "\n",
       "            format_group_Equipment  format_group_Media  format_group_Other  \\\n",
       "date                                                                         \n",
       "2005-04-13                     1.0              6397.0                32.0   \n",
       "2005-04-14                     1.0              4015.0                75.0   \n",
       "2005-04-15                     0.0              5351.0                51.0   \n",
       "2005-04-16                     0.0               552.0                 0.0   \n",
       "2005-04-17                     0.0              1555.0                 8.0   \n",
       "\n",
       "            format_group_Print  format_subgroup_Art  \\\n",
       "date                                                  \n",
       "2005-04-13             10041.0                  0.0   \n",
       "2005-04-14              6267.0                  0.0   \n",
       "2005-04-15              7494.0                  0.0   \n",
       "2005-04-16               806.0                  0.0   \n",
       "2005-04-17              2992.0                  0.0   \n",
       "\n",
       "            format_subgroup_Audio Disc  format_subgroup_Audio Tape  ...  \\\n",
       "date                                                                ...   \n",
       "2005-04-13                      1874.0                        63.0  ...   \n",
       "2005-04-14                      1245.0                        31.0  ...   \n",
       "2005-04-15                      1462.0                        54.0  ...   \n",
       "2005-04-16                       175.0                         8.0  ...   \n",
       "2005-04-17                       499.0                        10.0  ...   \n",
       "\n",
       "            format_subgroup_Video Tape  category_group_Fiction  \\\n",
       "date                                                             \n",
       "2005-04-13                      1878.0                  8189.0   \n",
       "2005-04-14                      1115.0                  5276.0   \n",
       "2005-04-15                      1721.0                  6357.0   \n",
       "2005-04-16                       163.0                   567.0   \n",
       "2005-04-17                       480.0                  2017.0   \n",
       "\n",
       "            category_group_Interlibrary Loan  category_group_Language  \\\n",
       "date                                                                    \n",
       "2005-04-13                              32.0                    370.0   \n",
       "2005-04-14                              73.0                    272.0   \n",
       "2005-04-15                              50.0                    302.0   \n",
       "2005-04-16                               0.0                     29.0   \n",
       "2005-04-17                               8.0                    177.0   \n",
       "\n",
       "            category_group_Nonfiction  category_group_Other  \\\n",
       "date                                                          \n",
       "2005-04-13                     6719.0                1143.0   \n",
       "2005-04-14                     4104.0                 621.0   \n",
       "2005-04-15                     5166.0                1014.0   \n",
       "2005-04-16                      666.0                  95.0   \n",
       "2005-04-17                     2145.0                 203.0   \n",
       "\n",
       "            category_group_Reference  age_group_Adult  age_group_Juvenile  \\\n",
       "date                                                                        \n",
       "2005-04-13                      18.0          11257.0              4613.0   \n",
       "2005-04-14                      12.0           6726.0              3381.0   \n",
       "2005-04-15                       7.0           8795.0              3747.0   \n",
       "2005-04-16                       1.0            950.0               367.0   \n",
       "2005-04-17                       5.0           3035.0              1349.0   \n",
       "\n",
       "            age_group_Teen  \n",
       "date                        \n",
       "2005-04-13           601.0  \n",
       "2005-04-14           251.0  \n",
       "2005-04-15           354.0  \n",
       "2005-04-16            41.0  \n",
       "2005-04-17           171.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine with total checkouts per day\n",
    "df_counts = pd.concat([df.groupby('date').size(), df_counts], axis=1)\n",
    "\n",
    "# rename target column\n",
    "df_counts.columns = ['total_checkouts'] + list(df_counts.columns[1:])\n",
    "\n",
    "# take a look\n",
    "df_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíæ Save/Load item counts DataFrame \n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to save\n",
    "df_counts.to_pickle(f'data/seattle_lib_counts.pkl', compression='gzip')\n",
    "\n",
    "# # uncomment to load\n",
    "# df_counts = pd.read_pickle('data/seattle_lib_counts.pkl', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, how incredible to have been able to distill that gigantic dataset into one that takes less than a second to save/load and is all of 257 KB.\n",
    "\n",
    "# Next notebook: [EDA](02_eda.ipynb)\n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]\n",
    "\n",
    "- The next notebook includes exploring and analyzing both the larger checkouts dataset and the item counts dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
