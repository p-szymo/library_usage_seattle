{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Usage in Seattle, 2005-2020\n",
    "\n",
    "## Data Cleaning\n",
    "\n",
    "The data is the [Checkouts by Title (Physical Items)](https://data.seattle.gov/Community/Checkouts-By-Title-Physical-Items-/5src-czff) dataset from [Seattle Open Data](https://data.seattle.gov/) and was downloaded on December 15, 2020.\n",
    "\n",
    "This notebook is designed to load a downloaded CSV file, merge it with item-specific information, convert it to a time-series-ready DataFrame, and save that as a compressed pickle file.\n",
    "\n",
    "*Note: This dataset is updated weekly; the more data, the longer the load times will be.*\n",
    "\n",
    "In the future, it may be a good idea to look into adding [API](https://dev.socrata.com/foundry/data.seattle.gov/5src-czff) calls into the pipeline, so as to quickly and easily add on the additional weekly data.\n",
    "\n",
    "*Note: Any cell that uses the built-in magic command* `%%time` *takes a significant (or at least not insignificant) time to run.*\n",
    "\n",
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard dataframe packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# saving packages\n",
    "import pickle\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load checkout data\n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]\n",
    "\n",
    "Since the data set is so large, I'll specify only the columns that I want in the DataFrame. This will effectively drop the following columns:\n",
    "- `ID`\n",
    "- `CheckoutYear`\n",
    "- `CallNumber`\n",
    "- `BibNumber`\n",
    "- `ItemBarcode`\n",
    "- `ItemType`\n",
    "    \n",
    "I want to note that the `ItemType` and `Collection` columns are very similar, but the code in the `Collection` column contains more information within the `category_group` column that I add onto the DataFrame using the `data_dictionary.csv` file ([see below](#Load-other-info-from-data-dictionary-and-merge-onto-checkouts-dataset)). More specifically, the `ItemType` code yields mostly \"Miscellaneous\" results, whereas the `Collection` code yields differentiates between \"Fiction\" and \"Nonfiction\", among others. This could be useful information later on, so I found it best to drop the `ItemType` column.\n",
    "\n",
    "Note: In the future, I may consider using this [dataset](https://data.seattle.gov/Community/Library-Collection-Inventory/6vkj-f5xf) to add on branch information (i.e. which branch an item was checked out from), although this data is rather limited (due to privacy concerns) and incomplete (only appears to be collected beginning in 2017). In order to do that I would need to use the `BibNumber` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 24s, sys: 5min 34s, total: 9min 58s\n",
      "Wall time: 15min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# columns to load\n",
    "usecols = ['Collection', 'ItemTitle', 'Subjects', 'CheckoutDateTime']\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv('data/Checkouts_By_Title__Physical_Items_.csv',\n",
    "#                  nrows=10000000,\n",
    "                 usecols=usecols)\n",
    "\n",
    "# rename columns to my preferred format\n",
    "df.columns = ['collection', 'title', 'subjects', 'date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: While it only took about 25 seconds to load 10 million rows, it takes about 25 minutes to load 106.5 million rows with the same number (5) of columns. In my latest update, I brought it down to 4 columns, which decreased load time to 15.5 minutes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection</th>\n",
       "      <th>title</th>\n",
       "      <th>subjects</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nadvd</td>\n",
       "      <td>Firewall</td>\n",
       "      <td>Kidnapping Drama, Video recordings for the hea...</td>\n",
       "      <td>02/13/2008 07:38:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nanf</td>\n",
       "      <td>best baby shower book a complete guide for par...</td>\n",
       "      <td>Showers Parties</td>\n",
       "      <td>07/23/2008 02:53:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nyfic</td>\n",
       "      <td>Uglies</td>\n",
       "      <td>Fantasy, Teenage girls Fiction, Beauty Persona...</td>\n",
       "      <td>12/23/2009 04:20:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>napar</td>\n",
       "      <td>doula guide to birth secrets every pregnant wo...</td>\n",
       "      <td>Doulas, Childbirth</td>\n",
       "      <td>11/16/2010 12:04:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>canf</td>\n",
       "      <td>Salmon a cookbook</td>\n",
       "      <td>Cookery Salmon</td>\n",
       "      <td>04/26/2009 01:29:00 PM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  collection                                              title  \\\n",
       "0      nadvd                                           Firewall   \n",
       "1       nanf  best baby shower book a complete guide for par...   \n",
       "2      nyfic                                             Uglies   \n",
       "3      napar  doula guide to birth secrets every pregnant wo...   \n",
       "4       canf                                  Salmon a cookbook   \n",
       "\n",
       "                                            subjects                    date  \n",
       "0  Kidnapping Drama, Video recordings for the hea...  02/13/2008 07:38:00 PM  \n",
       "1                                    Showers Parties  07/23/2008 02:53:00 PM  \n",
       "2  Fantasy, Teenage girls Fiction, Beauty Persona...  12/23/2009 04:20:00 PM  \n",
       "3                                 Doulas, Childbirth  11/16/2010 12:04:00 PM  \n",
       "4                                     Cookery Salmon  04/26/2009 01:29:00 PM  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106534901, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.4 s, sys: 1min 31s, total: 2min 15s\n",
      "Wall time: 3min 47s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "collection          0\n",
       "title          900912\n",
       "subjects      1649522\n",
       "date                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# check for nan values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE: Even checking for NaN values takes a significant amount of time with this many rows.*\n",
    "\n",
    "The most important columns (`collection` and `date`) have no NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collection    object\n",
       "title         object\n",
       "subjects      object\n",
       "date          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check datatypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert `date` column to datetime\n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'02/13/2008 07:38:00 PM'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at an example before conversion\n",
    "df.loc[0, 'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the format\n",
    "dt_format = '%m/%d/%Y %I:%M:%S %p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 20s, sys: 14.7 s, total: 6min 34s\n",
      "Wall time: 6min 36s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.date(2008, 2, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# convert to datetime, dropping the hour-minute-second stamp using the `dt.date` attribute\n",
    "df['date'] = pd.to_datetime(df.date, format=dt_format).dt.date\n",
    "\n",
    "# confirm it worked\n",
    "df.loc[0, 'date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load other info from data dictionary and merge onto checkouts dataset\n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>description</th>\n",
       "      <th>code_type</th>\n",
       "      <th>format_group</th>\n",
       "      <th>format_subgroup</th>\n",
       "      <th>category_group</th>\n",
       "      <th>category_subgroup</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cazover</td>\n",
       "      <td>CA7-zine collection oversize</td>\n",
       "      <td>ItemCollection</td>\n",
       "      <td>Print</td>\n",
       "      <td>Book</td>\n",
       "      <td>Periodical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>caziner</td>\n",
       "      <td>CA7-zine collection reference</td>\n",
       "      <td>ItemCollection</td>\n",
       "      <td>Print</td>\n",
       "      <td>Book</td>\n",
       "      <td>Periodical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cazval</td>\n",
       "      <td>CA7-zine collection valuable mat.</td>\n",
       "      <td>ItemCollection</td>\n",
       "      <td>Print</td>\n",
       "      <td>Book</td>\n",
       "      <td>Periodical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nga</td>\n",
       "      <td>Northgate Branch</td>\n",
       "      <td>Location</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hip</td>\n",
       "      <td>High Point Branch</td>\n",
       "      <td>Location</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      code                        description       code_type format_group  \\\n",
       "0  cazover       CA7-zine collection oversize  ItemCollection        Print   \n",
       "1  caziner      CA7-zine collection reference  ItemCollection        Print   \n",
       "2   cazval  CA7-zine collection valuable mat.  ItemCollection        Print   \n",
       "3      nga                   Northgate Branch        Location          NaN   \n",
       "4      hip                  High Point Branch        Location          NaN   \n",
       "\n",
       "  format_subgroup category_group category_subgroup age_group  \n",
       "0            Book     Periodical               NaN     Adult  \n",
       "1            Book     Periodical               NaN     Adult  \n",
       "2            Book     Periodical               NaN     Adult  \n",
       "3             NaN            NaN               NaN       NaN  \n",
       "4             NaN            NaN               NaN       NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "dd = pd.read_csv('data/data_dictionary.csv')\n",
    "\n",
    "# rename columns to my preferred format\n",
    "dd.columns = ['code', 'description', 'code_type', 'format_group', 'format_subgroup', \n",
    "              'category_group', 'category_subgroup', 'age_group']\n",
    "\n",
    "# take a look\n",
    "dd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape\n",
    "dd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code                 object\n",
       "description          object\n",
       "code_type            object\n",
       "format_group         object\n",
       "format_subgroup      object\n",
       "category_group       object\n",
       "category_subgroup    object\n",
       "age_group            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check datatypes\n",
    "dd.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I will only be using information from codes whose type is \"ItemCollection\", I'll subset the data dictionary down to just those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to only collection codes\n",
    "dd = dd[dd.code_type == 'ItemCollection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code                   0\n",
       "description            0\n",
       "code_type              0\n",
       "format_group           0\n",
       "format_subgroup       28\n",
       "category_group         2\n",
       "category_subgroup    391\n",
       "age_group              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for nan values\n",
    "dd.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, with the size of the eventual DataFrame in mind, I want to drop any unnecessary columns before merging, so I'll drop the following columns:\n",
    "- `description`, since that is superfluous information for this project\n",
    "- `code_type`, since that is superfluous information\n",
    "- `category_subgroup`, since that is mostly NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "dd.drop(columns=['description', 'code_type', 'category_subgroup'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of columns to convert\n",
    "to_convert = ['format_group', 'format_subgroup', 'category_group', 'age_group']\n",
    "\n",
    "# convert to category datatype\n",
    "dd[to_convert] = dd[to_convert].apply(pd.Categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code                 object\n",
       "format_group       category\n",
       "format_subgroup    category\n",
       "category_group     category\n",
       "age_group          category\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm new datatypes\n",
    "dd.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 2min 17s, total: 3min 22s\n",
      "Wall time: 5min 6s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection</th>\n",
       "      <th>title</th>\n",
       "      <th>subjects</th>\n",
       "      <th>date</th>\n",
       "      <th>code</th>\n",
       "      <th>format_group</th>\n",
       "      <th>format_subgroup</th>\n",
       "      <th>category_group</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nadvd</td>\n",
       "      <td>Firewall</td>\n",
       "      <td>Kidnapping Drama, Video recordings for the hea...</td>\n",
       "      <td>2008-02-13</td>\n",
       "      <td>nadvd</td>\n",
       "      <td>Media</td>\n",
       "      <td>Video Disc</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nadvd</td>\n",
       "      <td>Marley me</td>\n",
       "      <td>Comedy films, Married people Drama, Philadelph...</td>\n",
       "      <td>2009-07-03</td>\n",
       "      <td>nadvd</td>\n",
       "      <td>Media</td>\n",
       "      <td>Video Disc</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nadvd</td>\n",
       "      <td>Six feet under The complete fourth season</td>\n",
       "      <td>Video recordings for the hearing impaired, Pro...</td>\n",
       "      <td>2008-10-26</td>\n",
       "      <td>nadvd</td>\n",
       "      <td>Media</td>\n",
       "      <td>Video Disc</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nadvd</td>\n",
       "      <td>Doctor Who The next doctor</td>\n",
       "      <td>London England Drama, Doctor Who Fictitious ch...</td>\n",
       "      <td>2010-11-10</td>\n",
       "      <td>nadvd</td>\n",
       "      <td>Media</td>\n",
       "      <td>Video Disc</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nadvd</td>\n",
       "      <td>School ties</td>\n",
       "      <td>Antisemitism Drama, Video recordings for the h...</td>\n",
       "      <td>2008-12-28</td>\n",
       "      <td>nadvd</td>\n",
       "      <td>Media</td>\n",
       "      <td>Video Disc</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  collection                                      title  \\\n",
       "0      nadvd                                   Firewall   \n",
       "1      nadvd                                  Marley me   \n",
       "2      nadvd  Six feet under The complete fourth season   \n",
       "3      nadvd                 Doctor Who The next doctor   \n",
       "4      nadvd                                School ties   \n",
       "\n",
       "                                            subjects        date   code  \\\n",
       "0  Kidnapping Drama, Video recordings for the hea...  2008-02-13  nadvd   \n",
       "1  Comedy films, Married people Drama, Philadelph...  2009-07-03  nadvd   \n",
       "2  Video recordings for the hearing impaired, Pro...  2008-10-26  nadvd   \n",
       "3  London England Drama, Doctor Who Fictitious ch...  2010-11-10  nadvd   \n",
       "4  Antisemitism Drama, Video recordings for the h...  2008-12-28  nadvd   \n",
       "\n",
       "  format_group format_subgroup category_group age_group  \n",
       "0        Media      Video Disc        Fiction     Adult  \n",
       "1        Media      Video Disc        Fiction     Adult  \n",
       "2        Media      Video Disc        Fiction     Adult  \n",
       "3        Media      Video Disc        Fiction     Adult  \n",
       "4        Media      Video Disc        Fiction     Adult  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# merge checkouts dataframe with info from data dictionary\n",
    "df_merged = df.merge(dd, left_on='collection', right_on='code')\n",
    "\n",
    "# take a look\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After merging, I can now drop the `collection` and `code` columns, since those are no longer necessary.\n",
    "\n",
    "*NOTE: Using the Pandas method `.drop()` was taking well over an hour, so I'm going to try to subset it below, to see if that works any faster.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 5s, sys: 21min 3s, total: 24min 9s\n",
      "Wall time: 48min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# list of columns to keep\n",
    "keep_cols = ['title', 'subjects', 'date', 'format_group', 'format_subgroup',\n",
    "             'category_group', 'age_group']\n",
    "\n",
    "# drop columns\n",
    "df_merged = df_merged[keep_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE: On the first run through, this only took about 25 minutes, but for some reason this time around it took over an hour!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set `date` column as index\n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 27s, sys: 17min 16s, total: 25min 43s\n",
      "Wall time: 49min 11s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subjects</th>\n",
       "      <th>date</th>\n",
       "      <th>format_group</th>\n",
       "      <th>format_subgroup</th>\n",
       "      <th>category_group</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-04-13</th>\n",
       "      <td>If I knew then</td>\n",
       "      <td>Fisher Amy 1974, Buttafuoco Joey, Attempted mu...</td>\n",
       "      <td>2005-04-13</td>\n",
       "      <td>Print</td>\n",
       "      <td>Book</td>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-13</th>\n",
       "      <td>Peach girl 4</td>\n",
       "      <td>Teenagers, Comic books strips etc</td>\n",
       "      <td>2005-04-13</td>\n",
       "      <td>Print</td>\n",
       "      <td>Book</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Teen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>England Fiction, Abandoned children Fiction, G...</td>\n",
       "      <td>2005-04-13</td>\n",
       "      <td>Print</td>\n",
       "      <td>Book</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-13</th>\n",
       "      <td>Devil in the dark</td>\n",
       "      <td>Love stories, Historical fiction, Yorkshire En...</td>\n",
       "      <td>2005-04-13</td>\n",
       "      <td>Print</td>\n",
       "      <td>Book</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-13</th>\n",
       "      <td>Random Zits</td>\n",
       "      <td>Graphic novels, American wit and humor Pictori...</td>\n",
       "      <td>2005-04-13</td>\n",
       "      <td>Print</td>\n",
       "      <td>Book</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Teen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        title  \\\n",
       "date                            \n",
       "2005-04-13     If I knew then   \n",
       "2005-04-13       Peach girl 4   \n",
       "2005-04-13                NaN   \n",
       "2005-04-13  Devil in the dark   \n",
       "2005-04-13        Random Zits   \n",
       "\n",
       "                                                     subjects        date  \\\n",
       "date                                                                        \n",
       "2005-04-13  Fisher Amy 1974, Buttafuoco Joey, Attempted mu...  2005-04-13   \n",
       "2005-04-13                  Teenagers, Comic books strips etc  2005-04-13   \n",
       "2005-04-13  England Fiction, Abandoned children Fiction, G...  2005-04-13   \n",
       "2005-04-13  Love stories, Historical fiction, Yorkshire En...  2005-04-13   \n",
       "2005-04-13  Graphic novels, American wit and humor Pictori...  2005-04-13   \n",
       "\n",
       "           format_group format_subgroup category_group age_group  \n",
       "date                                                              \n",
       "2005-04-13        Print            Book     Nonfiction     Adult  \n",
       "2005-04-13        Print            Book        Fiction      Teen  \n",
       "2005-04-13        Print            Book        Fiction     Adult  \n",
       "2005-04-13        Print            Book        Fiction     Adult  \n",
       "2005-04-13        Print            Book        Fiction      Teen  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# set `date` column as index and sort by index\n",
    "df_merged = df_merged.set_index(df_merged.date).sort_index()\n",
    "\n",
    "# take a look\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23 s, sys: 7min 46s, total: 8min 9s\n",
      "Wall time: 22min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# remove date from list of columns to keep, since that will be the new index\n",
    "keep_cols.remove('date')\n",
    "\n",
    "# drop date column\n",
    "df_merged = df_merged[keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106503843, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape\n",
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                object\n",
       "subjects             object\n",
       "format_group       category\n",
       "format_subgroup    category\n",
       "category_group     category\n",
       "age_group          category\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check datatypes\n",
    "df_merged.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: I may be able to drop even more columns (thinking especially of `title` and `subjects`), since I'll mostly be looking at sheer numbers of items checked out each day. I'll keep them in for now in case they end up being useful for EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ’¾ Save/Load\n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# uncomment to save\n",
    "with gzip.open('data/seattle_lib.pkl', 'wb') as goodbye:\n",
    "    pickle.dump(df_merged, goodbye, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# # uncomment to load\n",
    "# with gzip.open('data/seattle_lib.pkl', 'rb') as hello:\n",
    "#     df = pickle.load(hello)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: File size for 1 million rows is just under 38 MB; takes 25 seconds to save.\n",
    "\n",
    "#### NOTE: File size for 10 million rows is just under 405 MB; takes 4.5 minutes to save.\n",
    "\n",
    "As of now it appears to be scaling linearly. That means it may take around 45 minutes to save the entire DataFrame, which should be around 4 GB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRAVEYARD\n",
    "\n",
    "[[go back to the top](#Library-Usage-in-Seattle,-2005-2020)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "please break code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd[dd.code_type == 'ItemType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd[dd.code == 'nadvd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd[dd.code == 'acdvd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.code_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_item = dd[dd.code_type == 'ItemType'][['code', 'description', 'format_group', 'format_subgroup', 'category_group', \n",
    "             'category_subgroup', 'age_group']]\n",
    "\n",
    "dd_item.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_item2 = dd[dd.code_type == 'ItemCollection'][['code', 'description', 'format_group', 'format_subgroup', 'category_group', \n",
    "             'category_subgroup', 'age_group']]\n",
    "\n",
    "dd_item2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df.item_type.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_loc = dd[dd.code_type == 'Location'][['code', 'description']]\n",
    "\n",
    "dd_loc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.merge(dd_item, left_on='item_type', right_on='code')\n",
    "# test = test.merge(dd_loc, left_on='collection', right_on='code')\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.format_group.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.collection.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = df.merge(dd_item2, left_on='Collection', right_on='code')\n",
    "\n",
    "test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.groupby('format_group').category_group.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2.groupby('format_group').category_group.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd[dd.code == 'nybot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df.collection.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_loc.code.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[cod for cod in df.collection.unique() if cod in dd_loc.code.unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
